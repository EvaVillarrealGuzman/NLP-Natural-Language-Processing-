{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation using LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package webtext to\n",
      "[nltk_data]     C:\\Users\\69785hsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import webtext \n",
    "nltk.download('webtext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data\n",
    "text = open('sherlock_homes.txt', 'r').read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "561852"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map chars to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars:  59\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars: ', len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split up into subsequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 187271\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ï»¿adventure i. a scandal in bohemia\\n\\ni.', 'adventure i. a scandal in bohemia\\n\\ni.\\n\\nt', 'enture i. a scandal in bohemia\\n\\ni.\\n\\nto s']\n",
      "['\\n', 'o', 'h']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[:3])\n",
    "print(next_chars[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[False False False ... False False  True]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ...  True False False]\n",
      "  ...\n",
      "  [ True False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]]\n",
      "\n",
      " [[False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  ...\n",
      "  [ True False False ... False False False]\n",
      "  [ True False False ... False False False]\n",
      "  [False False False ... False False False]]\n",
      "\n",
      " [[False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  ...\n",
      "  [False False False ... False False False]\n",
      "  [False  True False ... False False False]\n",
      "  [False False False ... False False False]]]\n",
      "[[ True False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False  True False False False False False False False False\n",
      "  False False False False False False False False False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False  True False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False]]\n"
     ]
    }
   ],
   "source": [
    "print(x[:3])\n",
    "print(y[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath = \"book.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss',\n",
    "                             verbose=1, save_best_only=True,\n",
    "                             mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=1, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [print_callback, checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "187271/187271 [==============================] - 63s 335us/step - loss: 1.9745\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ion, but he half opened his\n",
      "lids now and\"\n",
      "ion, but he half opened his\n",
      "lids now and and a crient of the should she was a stare of the should not with the stretter of the stretter with a start of the strang and the strange of the stare and the sheen a confice and the stretter was a started to my served to the stret with her she was a stark with a me the man and were were with a start of the should as the man and read to the seen to me stret of the street and the stretter of the s\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ion, but he half opened his\n",
      "lids now and\"\n",
      "ion, but he half opened his\n",
      "lids now and we mr. which we was a minnt surned the mat street of her had been me undersartand a was the manked to she are will to as freen and that we well she was to drive your to me bend from all contre, in the drewn of a mere in a last abmetter with my correct?\"\n",
      "\n",
      "\"i the is the sereation of the seener of the twonk to mr. which he she waited a trad been a dredd to the matter two mr. and the river in the mat\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ion, but he half opened his\n",
      "lids now and\"\n",
      "ion, but he half opened his\n",
      "lids now and his apposling in stard. howid mane of mr. wite prownous mr. and recunniog-pritench out a stairar in a seffinion. rean harroned yewing of the preads in the\n",
      "sproked you seepited dotr,.\"\n",
      "\n",
      "\"ase he was let leps tilly. he sand agealisaw we apovite, man, and unden yes to could frovely, withfrimm by\n",
      "brong tot werr teind of count creeninglers dued in the obter in ille glawn your armarmed. it mr. beple had\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ion, but he half opened his\n",
      "lids now and\"\n",
      "ion, but he half opened his\n",
      "lids now and angeal in twe doumced perartites, antwe her beciageet,\" wanlefgome in at prom onning evisiin a hott frinke steet were grsked, she ghamg, wrent known the learily prestirely\n",
      "me as no\n",
      "fore. he ascane?, with e. proked we doaph tecder. 'ftharle wroked, i\n",
      "sas .\n",
      "\n",
      "\"where as  stild grvends up i to foulewurnor with there pasted the rownirasites- i lesmin to edoust, crank trle, whilk he wentullellake brewme\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.97454, saving model to book.hdf5\n",
      "Epoch 2/5\n",
      "187271/187271 [==============================] - 65s 347us/step - loss: 1.6388\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"hould say to this dear\n",
      "little woman to-n\"\n",
      "hould say to this dear\n",
      "little woman to-night in the strange of the street of the sone of the man had have so the stood at the strong of the strong of the strong at the strange of the sone that i have a street of the strong of the sone of the strong--there was a straighed as i was a son of the sone of the strong of the strange of the straighed that it was a street of the strong--there was a stare as a street of the strong--there is a son\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"hould say to this dear\n",
      "little woman to-n\"\n",
      "hould say to this dear\n",
      "little woman to-neath, i thougress that is he, there is other me that it is a soute of corted which was been all that i have one of it was the ment of a street, and i came it was son't pressed as my son, and as a small that is this should 'as arrible that i have the matter that he was so man a street, and she was the lotter of the dear and a singee there were a leave the tawn that was a little so that you are inte\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"hould say to this dear\n",
      "little woman to-n\"\n",
      "hould say to this dear\n",
      "little woman to-ner quiet of signes, whom a\n",
      "have badely aly as my\n",
      "rather.\"\n",
      "\n",
      "\"she casined in oen?\"\n",
      "\n",
      "\"ame, and abodtaply is-turser, he had sured, when to let ever younscects\n",
      "who well-glasters upon i asped such you. the should some, roustion?\"\n",
      "\n",
      "\"you reelled from ppour there would not wick then\"\n",
      "\n",
      "\"it was tolder him the morning asones\n",
      "tsaw aid away\n",
      "capd there, instelly frent it his reeper to\n",
      "she withestred to wiuled th\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"hould say to this dear\n",
      "little woman to-n\"\n",
      "hould say to this dear\n",
      "little woman to-nerkivion tract which evenemuct of sougge-?\" wait glarrdar reselver is, ese.\n",
      "\n",
      "\"whicgoted we is baker to meal leigh ture which leave, atond\n",
      "love there\n",
      "no darrote upon she was\n",
      "sperdoc. oreeve, use freallen. it said leistes,' i had heis\n",
      "ssoty appe once is him tharless. theo slitte frost two bliry, i listed the\n",
      "leturys edgrtilled her. thit the\n",
      "feaked greas\n",
      "whether fallisy. we ware\n",
      "marden\n",
      "grive hu dad o\n",
      "\n",
      "Epoch 00002: loss improved from 1.97454 to 1.63875, saving model to book.hdf5\n",
      "Epoch 3/5\n",
      "187271/187271 [==============================] - 64s 341us/step - loss: 1.5442\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ch throws up mud in that way, and then o\"\n",
      "ch throws up mud in that way, and then one in the matters of the street of\n",
      "the street of the street that i she had street the could the pressing of the street of the street of the face of the matters of the street of the street of the street of the street of the street as i should have the street of the street of the street of the matters of the street of the street of the street of the street of the streat of the streat of the street o\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ch throws up mud in that way, and then o\"\n",
      "ch throws up mud in that way, and then our glompled my thing the matters with the tradge and\n",
      "here is\n",
      "so now, he should have he had a street of the street and her unusially heavy, and i am his strong street of the man which i had realined the pown my side of the door, and the little course day in the long in\n",
      "the street that it is sight the read. it is the vise in all the first in this is any need and the bady of the face of the droot of\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ch throws up mud in that way, and then o\"\n",
      "ch throws up mud in that way, and then one as i with this\n",
      "ugklass which that i begreat the your\n",
      "little\n",
      "when mich\n",
      "of the\n",
      "faclary\n",
      "sournly\n",
      "without nover insiture or wookth take the lady, st lass tsmentitable it,\n",
      "sow my goot purchess. it the fryine, the pressers, ears and,\n",
      "\"i\n",
      "red-fatt me\n",
      "terriwifit chade in will, as who hear deped my wood?\"\n",
      "\n",
      "\"'i left hers, drees that i may 'to usion years, but i do do\n",
      "i have pred up it, so the wellw which w\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ch throws up mud in that way, and then o\"\n",
      "ch throws up mud in that way, and then oys in your remenish on\n",
      "rikelyihson blaviss stteelly at firingmet stinclel his unly?\"\n",
      "\n",
      "\"eelys on my\n",
      "vigled fut\n",
      "my eftair.white\n",
      "up, on one mand.\n",
      "\"hen sfering. a\n",
      "now, seerenly reco-liech\n",
      "pash the disham, the powice.\n",
      "\n",
      "\"well, therer o'.\n",
      "geety dishon inkness fewly still\n",
      "currooremeapone.\n",
      "\n",
      " the came lady?\n",
      "salsjuity. \"onle,\n",
      "when he is gromous, proatwand for reah less\n",
      "time.' should he i proctable\n",
      "my weft\n",
      "ad\n",
      "\n",
      "Epoch 00003: loss improved from 1.63875 to 1.54419, saving model to book.hdf5\n",
      "Epoch 4/5\n",
      "187271/187271 [==============================] - 64s 339us/step - loss: 1.4918\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" that i was addressing wilhelm gottsreic\"\n",
      " that i was addressing wilhelm gottsreich of the first of the chair of the chair of the chair of the door when i should be a confired to the confice. we have have been and confired to the sound and be a states who have a confice of the most of the door and an entered to the confice of the man who have been with the station of the station. the confice. i should be a confice of the confice. i was to the sound of the confice of the most of\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" that i was addressing wilhelm gottsreic\"\n",
      " that i was addressing wilhelm gottsreich of the street. it is the room, and were without to the streats from the man that i saw holmes was it surning my of the\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cause. it was the colonel day it have have been some as is in the place and all part of a confice. with for his firse what was the little change to all\n",
      "think that the woman, and that i have a sonfice of the bedge-look. when i have not tell us an is perhaps upon the fact of the d\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" that i was addressing wilhelm gottsreic\"\n",
      " that i was addressing wilhelm gottsreichet a rited apray to openry and amiugion very keaid and love. a timent and his of the\n",
      "chill window, it oher that i cut me holserpie a verdar, and give papered double.\n",
      "\n",
      "\"bere-poor me an\n",
      "ones ago the curmmind stone of the use a yougg him. it on youf at just to a grave. he cousming in drunged at adventure emplies, and stabatoble doubt some\n",
      "hay unname, though the same's but hen my a noble t. hown oh t\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" that i was addressing wilhelm gottsreic\"\n",
      " that i was addressing wilhelm gottsreich hathinghiow. thowche. grompled, we slooge, with a duries.\"\n",
      "he clear.\n",
      "\n",
      "\"'my sposiut. bow twelves. bewation that tell drink, term and have usirenid\n",
      "little hands ofe in\n",
      "the\n",
      "chance and mys\n",
      "drawn\n",
      "of the mattered at a, letted\n",
      "his till sore, knack which is some pactent. year\n",
      "that the tall centrra-upsmaired.\"\n",
      "\n",
      "\"as i would, but with entish to diarravsiro, as we have little bebroudound in. whosterrese, ba\n",
      "\n",
      "Epoch 00004: loss improved from 1.54419 to 1.49179, saving model to book.hdf5\n",
      "Epoch 5/5\n",
      "187271/187271 [==============================] - 62s 331us/step - loss: 1.4617\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"nd that i was miss alice's friend\n",
      "too.\n",
      "\n",
      "\"\n",
      "nd that i was miss alice's friend\n",
      "too.\n",
      "\n",
      "\"it was a start that we have been any one of the countrary. then he was not the morning of the station of the country. then then then she was a fortune of the man which i was a started upon the station of the proture of the morning--and then i shall be the state of the standing of the continular was any\n",
      "fortune to the statement and read the stuating-beak the statement of the station of the man whi\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"nd that i was miss alice's friend\n",
      "too.\n",
      "\n",
      "\"\n",
      "nd that i was miss alice's friend\n",
      "too.\n",
      "\n",
      "\"then we was to rearey to a st. you have no doubt in the would then i shall not be had a part and\n",
      "all there was a morning-room and not weakting-rooms with an all many so that he had been do not not been and was in the morning and with an the street. and then wene one and and then you have been care, for the man which i have do not tell her k. we thought she may was then as i was on the charre and \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"nd that i was miss alice's friend\n",
      "too.\n",
      "\n",
      "\"\n",
      "nd that i was miss alice's friend\n",
      "too.\n",
      "\n",
      "\"then at movericad of the\n",
      "gear\n",
      "into the hugrapetry enucass, with crilk four. behild upon, mr. wish at the still shot he he\n",
      "haly. \"it was not been risers. we much realidel if yet st cien plvents my be id to gings that it was\n",
      "not hard which within i was open us her minutive myself anythutawt. there is\n",
      "constailed where you wish all the legged bogds, and and fr graws was i realishable something my inw\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"nd that i was miss alice's friend\n",
      "too.\n",
      "\n",
      "\"\n",
      "nd that i was miss alice's friend\n",
      "too.\n",
      "\n",
      "\"wene recarened\n",
      "bridg-met side no confult and he discilled alige of mrarfthable hind, so not englioa would \"vernotsent was shoped heavd mr. young none brucks, buf cellucatice better girons which they a\n",
      "reasulll, was thrist. he was watcopingalod showe answered poored\n",
      "count. with ofs, to leest nothing jurd-. which woterered ple enouns. he had sake metaor understand. by an\n",
      "tights, or his begge, artil\n",
      "\n",
      "Epoch 00005: loss improved from 1.49179 to 1.46167, saving model to book.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1be28b83240>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=128, epochs=5, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, diversity):\n",
    "    # Get random starting text\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l excuse me if\n",
      "i say that i cannot see however, was she was a man which he was the strange to the read of the statement that i have been any one of the strange of a bard of the station of the stall mine to the stall with and then the standing of the side of the start of the man which i should be the station of the side of the morning, and we went to the stall would be the statement of the state of the wead, and then he said the man which i have not not been and then i was a start of the station of the station of the cark to make his h\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(500, 0.2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
