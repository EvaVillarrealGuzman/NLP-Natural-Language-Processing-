# NLP (Natural Language Processing)

Natural language processing (NLP) is the ability of a computer program to understand human language as it is spoken.<br>

This repository contains Ipython notebooks and datasets for the projects related to NLP.

# Content

- 1)- AI- Chatbot using simple NLP concepts

- 2)- Auto-Tagging for single and multi-label classes

- 3)- Binary Classifier

- 4)- Sentiment Analysis for emerging technology of Autonomous vehicle using Crowd Flower dataset

- 5)- Customized named entity recognition problem using rule based method

- 6)- Resturant Customer Review analysis

- 7)- Indian Demonetization Opinion Analysis using social media dataset

- 8)- Detecting Programming Languages using Rule based method

- 9)- Document Similarity using NLP

- 10)- Understanding Eli5 library in Python

- 11)- Ecosystem using NLP

- 12)- Entity Extraction from raw text using flair

- 13)- Detecting Fake news 

- 14)- Hate speech identification 

- 15)- Innovation related topic extraction

- 16)- Keyword extraction using TF-IDF

- 17)- Label extraction using newspaper dataset

- 18)- Working with NIPS dataset

- 19)- Neural Machine Translation

- 20)- Named Entity Recognition for PDF format documents

- 21)- Opinion Mining

- 22)- Sentiment Analysis

- 23)- Spacy Tutorial

- 24)- Spam SMS Detection

- 25)- Text parsing for PDF files

- 26)- Basics of text analytics using Spacy

- 27)- Text classification in innovation studies

- 28)- Text generation using LSTM

- 29)- Understanding sentiment analysis concept with code+theory

- 30)- Pytorch tutorials

- 31)- Word2Vec for word embeddings application


# Modules

For data processing : pandas, numpy, eli5 <br>
For visualization : matplotlib, seaborn , plotly, TabPy <br>
For machine learning : sklearn, SciPy <br>
Web Scrapping : Beautifulsoup, Urllib , Scrapy,pdfminer,PyPDF2 <br>
For text mining : spacy, nltk,re, TextBlob, Gensim <br>
For deep learning : pytorch, tensorflow, keras <br>
For named Entity: Spacy, TextRank, Displacy, Flair

# References

- Attention: https://medium.com/datalogue/attention-in-keras-1892773a4f22
- Attention-model: Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. In Advances in neural information processing systems (pp. 5998-6008).
- Attention model wrapper: https://github.com/neonbjb/ml-notebooks/blob/master/keras-seq2seq-with-attention/keras_translate_notebook.ipynb
- Eng-Fr: https://medium.com/@dev.elect.iitd/neural-machine-translation-using-word-level-seq2seq-model-47538cba8cd7
- PyTorch: https://pytorch.org/tutorials/ <br>
- Flair: https://research.zalando.com/welcome/mission/research-projects/flair-nlp/
- https://keras.io/layers/embeddings/
- https://keras.io/preprocessing/text/
- Spacy: https://nlpforhackers.io/complete-guide-to-spacy/
- Gensim: https://pypi.org/project/gensim/
- Text BLob: https://textblob.readthedocs.io/en/dev/
- NLTK : https://www.nltk.org/
- Named Entity Recognition : https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da
- Spacy Documentation:https://spacy.io/usage/linguistic-features
- Explosion:https://github.com/koaning/spacy-youtube-material
- PyData 2018: Gilbert Francois Talk
- https://buhrmann.github.io/sklearn-pipelines.html
- RNN: http://karpathy.github.io/2015/05/21/rnn-effectiveness/
- LSTM: http://colah.github.io/posts/2015-08-Understanding-LSTMs/
- GRU: https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be
- GRU vs LSTM : https://datascience.stackexchange.com/questions/14581/when-to-use-gru-over-lstm
- Out-of-Vocab: https://medium.com/@shabeelkandi/handling-out-of-vocabulary-words-in-natural-language-processing-based-on-context-4bbba16214d5
- Seq2seq using neural net:Sutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks. In Advances in neural information processing systems (pp. 3104-3112).
- Seq2seq:https://medium.com/analytics-vidhya/a-must-read-nlp-tutorial-on-neural-machine-translation-the-technique-powering-google-translate-c5c8d97d7587
- Teacher forcing: https://machinelearningmastery.com/teacher-forcing-for-recurrent-neural-networks/
- Word-level seq2seq: https://towardsdatascience.com/word-level-english-to-marathi-neural-machine-translation-using-seq2seq-encoder-decoder-lstm-model-1a913f2dc4a7
- Word Embedding: https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa




# Credit

Sentdex, Siraj Raval,Explosion, medium, udemy,udacity, coursera, Vidya Analytics, Alice Zhou's blog and many more online blogs and courses that help me in learning concepts and ideas.
