{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)- Import key modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support both Python 2 and Python 3 with minimal overhead.\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# I am an engineer. I care only about error not warning. So, let's be maverick and ignore warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re    # for regular expressions \n",
    "import nltk  # for text manipulation \n",
    "import string \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import string \n",
    "\n",
    "#For Visuals\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 11, 8\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models and evaluation\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.classify.scikitlearn import SklearnClassifier # notice its from ntlk not sklearn\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Evaluation packages\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.7.7 64bit [MSC v.1916 64 bit (AMD64)]"
        },
        {
         "module": "IPython",
         "version": "7.13.0"
        },
        {
         "module": "OS",
         "version": "Windows 10 10.0.17763 SP0"
        },
        {
         "module": "pandas",
         "version": "1.0.3"
        },
        {
         "module": "numpy",
         "version": "1.18.1"
        },
        {
         "module": "nltk",
         "version": "3.5"
        },
        {
         "module": "seaborn",
         "version": "0.10.1"
        },
        {
         "module": "matplotlib",
         "version": "3.1.3"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.7.7 64bit [MSC v.1916 64 bit (AMD64)]</td></tr><tr><td>IPython</td><td>7.13.0</td></tr><tr><td>OS</td><td>Windows 10 10.0.17763 SP0</td></tr><tr><td>pandas</td><td>1.0.3</td></tr><tr><td>numpy</td><td>1.18.1</td></tr><tr><td>nltk</td><td>3.5</td></tr><tr><td>seaborn</td><td>0.10.1</td></tr><tr><td>matplotlib</td><td>3.1.3</td></tr><tr><td colspan='2'>Fri Jun 26 17:31:42 2020 W. Europe Daylight Time</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.7.7 64bit [MSC v.1916 64 bit (AMD64)] \\\\ \\hline\n",
       "IPython & 7.13.0 \\\\ \\hline\n",
       "OS & Windows 10 10.0.17763 SP0 \\\\ \\hline\n",
       "pandas & 1.0.3 \\\\ \\hline\n",
       "numpy & 1.18.1 \\\\ \\hline\n",
       "nltk & 3.5 \\\\ \\hline\n",
       "seaborn & 0.10.1 \\\\ \\hline\n",
       "matplotlib & 3.1.3 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Fri Jun 26 17:31:42 2020 W. Europe Daylight Time} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.7.7 64bit [MSC v.1916 64 bit (AMD64)]\n",
       "IPython 7.13.0\n",
       "OS Windows 10 10.0.17763 SP0\n",
       "pandas 1.0.3\n",
       "numpy 1.18.1\n",
       "nltk 3.5\n",
       "seaborn 0.10.1\n",
       "matplotlib 3.1.3\n",
       "Fri Jun 26 17:31:42 2020 W. Europe Daylight Time"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pip install version_information\n",
    "%reload_ext version_information\n",
    "%version_information pandas,numpy, nltk, seaborn, matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)- Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3655, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_excel('clean_3655_eng.xlsx')\n",
    "data=data.rename(columns={'Unnamed: 0':'random_columns'}) # a trick to tackle random index values\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random_columns</th>\n",
       "      <th>clean</th>\n",
       "      <th>firstmessage</th>\n",
       "      <th>dep</th>\n",
       "      <th>firstusedtextblock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>helloi tri appli voucher order receiv mail did...</td>\n",
       "      <td>Hello:&lt;br&gt;&lt;br&gt;I tried to apply a voucher to th...</td>\n",
       "      <td>Shipping issues</td>\n",
       "      <td>nichtkombiwb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>wow wow wow im love acryl cover pro photo book...</td>\n",
       "      <td>WOW WOW WOW! I'm so in love with my acrylic co...</td>\n",
       "      <td>Customer feedback</td>\n",
       "      <td>feedback</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   random_columns                                              clean  \\\n",
       "0               0  helloi tri appli voucher order receiv mail did...   \n",
       "1               1  wow wow wow im love acryl cover pro photo book...   \n",
       "\n",
       "                                        firstmessage                dep  \\\n",
       "0  Hello:<br><br>I tried to apply a voucher to th...    Shipping issues   \n",
       "1  WOW WOW WOW! I'm so in love with my acrylic co...  Customer feedback   \n",
       "\n",
       "  firstusedtextblock  \n",
       "0       nichtkombiwb  \n",
       "1           feedback  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping response of Bot as target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all samples that are above 100 atleast\n",
    "#counts=data['firstusedtextblock'].value_counts()\n",
    "#df = data.loc[data['firstusedtextblock'].isin(counts.index[counts > 30])]\n",
    "#f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.firstusedtextblock.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3)- Vectorization\n",
    "\n",
    "- word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling any clean values in data with other\n",
    "\n",
    "df=data.fillna('Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "random_columns        0\n",
       "clean                 0\n",
       "firstmessage          0\n",
       "dep                   0\n",
       "firstusedtextblock    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3655,)\n",
      "(3655,)\n"
     ]
    }
   ],
   "source": [
    "features=df['clean']\n",
    "labels=df['dep']\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import gensim\n",
    "from tqdm import tqdm \n",
    "tqdm.pandas(desc=\"progress-bar\") \n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2167305, 2636780)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = df['clean'].apply(lambda x: x.split()) # tokenizing\n",
    "\n",
    "model_w2v = gensim.models.Word2Vec(\n",
    "            tokenized_text,\n",
    "            size=200, # desired no. of features/independent variables\n",
    "            window=5, # context window size\n",
    "            min_count=2,\n",
    "            sg = 1, # 1 for skip-gram model\n",
    "            hs = 0,\n",
    "            negative = 10, # for negative sampling i.e class with other types\n",
    "            workers= 2, # no.of cores\n",
    "            seed = 34) \n",
    "\n",
    "model_w2v.train(tokenized_text, total_examples= len(data['clean']), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.11725056e-02,  1.97871223e-01,  1.90359533e-01, -4.12314286e-04,\n",
       "        1.00462802e-01,  4.86835778e-01, -2.36125439e-01,  5.76793075e-01,\n",
       "        1.99946359e-01,  2.42573321e-01, -2.06356317e-01,  4.33460660e-02,\n",
       "        5.68535626e-01, -3.41432661e-01,  2.69370228e-01, -1.28365248e-01,\n",
       "       -8.93084258e-02,  1.70563430e-01,  9.45942923e-02, -3.79822522e-01,\n",
       "       -5.22737861e-01, -6.56142011e-02,  3.63920063e-01,  1.65488988e-01,\n",
       "        2.51693487e-01,  1.05079897e-01, -1.57427803e-01,  2.17064142e-01,\n",
       "       -1.92808993e-02,  5.02826497e-02, -5.31077087e-02,  5.12462795e-01,\n",
       "        1.20442227e-01,  2.29578599e-01, -4.27521877e-02, -2.95929909e-01,\n",
       "       -4.13798213e-01,  3.30416918e-01, -1.03047132e-01,  3.23975295e-01,\n",
       "       -3.40579063e-01,  8.01496208e-02, -2.20354170e-01,  1.92271695e-01,\n",
       "        2.25173414e-01,  5.27483150e-02, -2.83559501e-01,  1.33370250e-01,\n",
       "        3.67361195e-02, -1.39613226e-01,  1.40060801e-02,  2.29654491e-01,\n",
       "       -9.43983197e-02,  2.09927171e-01, -1.41713366e-01,  9.85591114e-02,\n",
       "        1.64644077e-01, -1.99644953e-01, -1.97059929e-01,  1.79065645e-01,\n",
       "        5.62927902e-01, -3.79761457e-01,  5.37555665e-02, -1.61525577e-01,\n",
       "        7.55904317e-02,  4.40899223e-01, -3.88904124e-01, -3.84684913e-02,\n",
       "       -9.41636860e-02,  3.31762075e-01, -3.78954381e-01, -2.80710291e-02,\n",
       "        3.26448083e-02, -3.68148476e-01,  4.23455477e-01, -5.73610306e-01,\n",
       "        5.44382259e-02, -2.33466357e-01,  2.59181648e-01,  2.40389541e-01,\n",
       "        1.04167886e-01,  2.51076311e-01,  1.65082633e-01, -8.24555084e-02,\n",
       "        1.90167204e-01, -9.56332386e-02, -2.35222578e-01,  3.33040446e-01,\n",
       "       -2.32616648e-01, -2.64561415e-01,  9.71250609e-02,  7.43587077e-01,\n",
       "       -2.17730194e-01,  6.13334887e-02, -3.32571179e-01, -3.26248318e-01,\n",
       "        1.36064246e-01,  8.21092650e-02, -1.21492138e-02, -2.73197502e-01,\n",
       "       -6.79120496e-02, -1.04914747e-01, -3.49517435e-01,  1.11801317e-02,\n",
       "       -2.05743283e-01, -3.08490805e-02,  5.37469745e-01,  2.01568931e-01,\n",
       "        1.28049970e-01, -2.14610726e-01,  4.09155674e-02,  1.03072338e-01,\n",
       "        3.97454530e-01,  5.67626245e-02,  9.23573747e-02, -2.96886861e-01,\n",
       "        2.84413397e-01, -2.80032363e-02,  3.61769833e-02, -7.51957893e-02,\n",
       "       -1.83665782e-01, -6.61356032e-01, -5.89890659e-01,  2.21107304e-01,\n",
       "       -5.95684014e-02,  5.24288509e-03,  1.63326070e-01,  6.20770976e-02,\n",
       "       -1.77624226e-01, -1.42718181e-01,  5.09824157e-01, -2.14271292e-01,\n",
       "        2.84450650e-01,  1.88074604e-01,  8.27035680e-02, -4.23687994e-01,\n",
       "       -4.03292291e-02, -5.06370902e-01,  3.82506102e-02,  6.72563463e-02,\n",
       "       -6.80199564e-02, -1.42436856e-02,  2.47327000e-01, -3.57525259e-01,\n",
       "        1.39510795e-01,  7.38697201e-02, -5.24238408e-01,  2.08602339e-01,\n",
       "        3.57055753e-01, -6.92605227e-02,  5.67487717e-01, -2.58331299e-01,\n",
       "        5.38874418e-02, -7.68219084e-02,  4.02519941e-01,  3.71657193e-01,\n",
       "       -2.45138958e-01,  9.49661583e-02, -4.32579257e-02,  1.88734308e-01,\n",
       "       -3.81567180e-01, -2.82183021e-01,  1.37313619e-01, -2.99201846e-01,\n",
       "        3.98851156e-01, -1.74334437e-01,  3.67121518e-01,  1.63085118e-01,\n",
       "       -9.55553278e-02,  3.93619865e-01, -5.37272543e-03, -1.77888330e-02,\n",
       "        2.45149061e-01,  3.16412270e-01,  1.08390361e-01, -1.92647770e-01,\n",
       "        5.01748681e-01, -1.29173934e-01, -3.18610758e-01,  3.32814991e-01,\n",
       "        3.54865789e-01, -3.20243388e-01,  3.63036364e-01,  1.21352874e-01,\n",
       "       -5.87561578e-02, -1.61377758e-01,  2.70165533e-01,  5.50062537e-01,\n",
       "       -1.04836971e-01, -6.25781249e-03, -7.17507582e-03,  5.29926836e-01,\n",
       "       -2.26786032e-01, -4.48066145e-01, -9.96643975e-02,  3.24138179e-02,\n",
       "       -3.97171110e-01,  2.15480521e-01,  1.39173016e-01, -3.51908535e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv['saal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_w2v.wv['saal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.word2vec.Word2Vec"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.Preparing Vectors for text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model_w2v[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError: # handling the case where the token is not in vocabulary           \n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.Preparing word2vec feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.052964</td>\n",
       "      <td>-0.309100</td>\n",
       "      <td>-0.156003</td>\n",
       "      <td>-0.273249</td>\n",
       "      <td>0.180147</td>\n",
       "      <td>0.022185</td>\n",
       "      <td>-0.125600</td>\n",
       "      <td>0.005796</td>\n",
       "      <td>-0.111066</td>\n",
       "      <td>0.255735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220305</td>\n",
       "      <td>0.095240</td>\n",
       "      <td>0.212674</td>\n",
       "      <td>-0.300422</td>\n",
       "      <td>0.145420</td>\n",
       "      <td>0.089090</td>\n",
       "      <td>0.127892</td>\n",
       "      <td>0.057989</td>\n",
       "      <td>0.103869</td>\n",
       "      <td>0.001788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.126613</td>\n",
       "      <td>-0.115837</td>\n",
       "      <td>-0.098505</td>\n",
       "      <td>-0.132175</td>\n",
       "      <td>0.183805</td>\n",
       "      <td>0.117226</td>\n",
       "      <td>-0.113368</td>\n",
       "      <td>0.084798</td>\n",
       "      <td>0.042672</td>\n",
       "      <td>0.091176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203327</td>\n",
       "      <td>0.095713</td>\n",
       "      <td>0.129161</td>\n",
       "      <td>-0.267642</td>\n",
       "      <td>0.087197</td>\n",
       "      <td>0.010871</td>\n",
       "      <td>-0.159869</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>-0.067836</td>\n",
       "      <td>0.049211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.046056</td>\n",
       "      <td>-0.161739</td>\n",
       "      <td>-0.398194</td>\n",
       "      <td>-0.153053</td>\n",
       "      <td>0.323608</td>\n",
       "      <td>-0.052838</td>\n",
       "      <td>0.022553</td>\n",
       "      <td>-0.090688</td>\n",
       "      <td>0.068870</td>\n",
       "      <td>0.305390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081925</td>\n",
       "      <td>0.230162</td>\n",
       "      <td>-0.013826</td>\n",
       "      <td>-0.078384</td>\n",
       "      <td>0.098563</td>\n",
       "      <td>0.039796</td>\n",
       "      <td>0.085175</td>\n",
       "      <td>0.066815</td>\n",
       "      <td>-0.005773</td>\n",
       "      <td>-0.118223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.049999</td>\n",
       "      <td>-0.100877</td>\n",
       "      <td>-0.135427</td>\n",
       "      <td>-0.074134</td>\n",
       "      <td>0.218544</td>\n",
       "      <td>-0.098632</td>\n",
       "      <td>0.049040</td>\n",
       "      <td>0.093452</td>\n",
       "      <td>0.077910</td>\n",
       "      <td>0.136556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119776</td>\n",
       "      <td>0.209370</td>\n",
       "      <td>0.012688</td>\n",
       "      <td>-0.385181</td>\n",
       "      <td>0.136862</td>\n",
       "      <td>0.140701</td>\n",
       "      <td>-0.002442</td>\n",
       "      <td>-0.025570</td>\n",
       "      <td>0.099062</td>\n",
       "      <td>0.059733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016818</td>\n",
       "      <td>-0.233915</td>\n",
       "      <td>-0.090780</td>\n",
       "      <td>-0.109749</td>\n",
       "      <td>0.140512</td>\n",
       "      <td>0.111652</td>\n",
       "      <td>-0.130679</td>\n",
       "      <td>-0.117094</td>\n",
       "      <td>0.028222</td>\n",
       "      <td>0.274613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304981</td>\n",
       "      <td>-0.045720</td>\n",
       "      <td>0.102768</td>\n",
       "      <td>-0.271182</td>\n",
       "      <td>0.295810</td>\n",
       "      <td>0.187507</td>\n",
       "      <td>0.195698</td>\n",
       "      <td>0.078559</td>\n",
       "      <td>-0.189366</td>\n",
       "      <td>0.055345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.052964 -0.309100 -0.156003 -0.273249  0.180147  0.022185 -0.125600   \n",
       "1  0.126613 -0.115837 -0.098505 -0.132175  0.183805  0.117226 -0.113368   \n",
       "2  0.046056 -0.161739 -0.398194 -0.153053  0.323608 -0.052838  0.022553   \n",
       "3  0.049999 -0.100877 -0.135427 -0.074134  0.218544 -0.098632  0.049040   \n",
       "4  0.016818 -0.233915 -0.090780 -0.109749  0.140512  0.111652 -0.130679   \n",
       "\n",
       "        7         8         9    ...       190       191       192       193  \\\n",
       "0  0.005796 -0.111066  0.255735  ...  0.220305  0.095240  0.212674 -0.300422   \n",
       "1  0.084798  0.042672  0.091176  ...  0.203327  0.095713  0.129161 -0.267642   \n",
       "2 -0.090688  0.068870  0.305390  ...  0.081925  0.230162 -0.013826 -0.078384   \n",
       "3  0.093452  0.077910  0.136556  ...  0.119776  0.209370  0.012688 -0.385181   \n",
       "4 -0.117094  0.028222  0.274613  ...  0.304981 -0.045720  0.102768 -0.271182   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0  0.145420  0.089090  0.127892  0.057989  0.103869  0.001788  \n",
       "1  0.087197  0.010871 -0.159869  0.003409 -0.067836  0.049211  \n",
       "2  0.098563  0.039796  0.085175  0.066815 -0.005773 -0.118223  \n",
       "3  0.136862  0.140701 -0.002442 -0.025570  0.099062  0.059733  \n",
       "4  0.295810  0.187507  0.195698  0.078559 -0.189366  0.055345  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_arrays = np.zeros((len(tokenized_text), 200)) \n",
    "for i in range(len(tokenized_text)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_text[i], 200)\n",
    "    wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "wordvec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3655, 200)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4)- Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_curve,roc_auc_score,confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3655, 200)\n",
      "(3655,)\n"
     ]
    }
   ],
   "source": [
    "X=wordvec_df\n",
    "y=df['dep']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into training and validation set\n",
    "xtrain_word2vec, xvalid_word2vec, ytrain, yvalid = train_test_split(X, y,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2924, 200)\n",
      "(731, 200)\n",
      "(2924,)\n",
      "(731,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_word2vec.shape)\n",
    "print(xvalid_word2vec.shape)\n",
    "print(ytrain.shape)\n",
    "print(yvalid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "Extreme Gradient Boosting (xgboost) is an advanced implementation of gradient boosting algorithm. It has both linear model solver and tree learning algorithms. Its ability to do parallel computation on a single machine makes it extremely fast. It also has additional features for doing cross validation and finding important variables. There are many parameters which need to be controlled to optimize the model.\n",
    "\n",
    "Some key benefits of XGBoost are:\n",
    "\n",
    "Regularization - helps in reducing overfitting\n",
    "Parallel Processing - XGBoost implements parallel processing and is blazingly faster as compared to GBM.\n",
    "Handling Missing Values - It has an in-built routine to handle missing values.\n",
    "Built-in Cross-Validation - allows user to run a cross-validation at each iteration of the boosting process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice there is no sklearn ready made model therefore; I needed to use XGBoost from its main librrary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost using word2vecfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6060191518467852"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(max_depth=6, n_estimators=1000).fit(xtrain_word2vec, ytrain)\n",
    "prediction = xgb_model.predict_proba(xvalid_word2vec)\n",
    "prediction_class = xgb_model.predict(xvalid_word2vec)\n",
    "accuracy_score(yvalid, prediction_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'word2vec_xgb_model.sav'\n",
    "pickle.dump(xgb_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = loaded_model.predict_proba(xvalid_word2vec)\n",
    "prediction_class = loaded_model.predict(xvalid_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6060191518467852"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      precision    recall  f1-score   support\n",
      "\n",
      "                                   Customer feedback       0.64      0.59      0.61        78\n",
      "                       Data protection (Datenschutz)       1.00      0.75      0.86         4\n",
      "                                   Discovery voucher       0.00      0.00      0.00         4\n",
      "                                           Marketing       0.73      0.48      0.58        23\n",
      "                                    Order management       0.65      0.84      0.73       301\n",
      "                                 Payment (Bezahlung)       0.00      0.00      0.00        12\n",
      "                                   Product (Produkt)       0.67      0.21      0.32        19\n",
      "                                   Production delays       1.00      0.11      0.20         9\n",
      "                    Professional area (Profibereich)       0.71      0.29      0.42        17\n",
      "                                   Reseller workflow       1.00      0.75      0.86         4\n",
      "                                         Rücksendung       1.00      0.14      0.25         7\n",
      "                                       ShareWithSaal       0.74      0.75      0.75        57\n",
      "                                     Shipping issues       0.22      0.06      0.10        32\n",
      "                                Software/Webshop/App       0.58      0.39      0.46        88\n",
      "                                  Special conditions       0.80      0.44      0.57         9\n",
      "   product complaints - colours (Reklamation Farben)       0.67      0.11      0.19        18\n",
      "product complaints - products (Reklamation Produkte)       0.31      0.64      0.42        47\n",
      "product complaints - software (Reklamation Software)       0.00      0.00      0.00         2\n",
      "\n",
      "                                            accuracy                           0.61       731\n",
      "                                           macro avg       0.60      0.36      0.41       731\n",
      "                                        weighted avg       0.61      0.61      0.57       731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "18\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "print(labels.nunique())\n",
    "print(yvalid.nunique())\n",
    "print(ytrain.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other values are also very consistent.\n",
    "\n",
    "- accuracy = 57.8%\n",
    "- precision = 58%\n",
    "- recall = 58%\n",
    "- f-score = 55%\n",
    "- (test samples=731)\n",
    "- No. of classes in test data = 18\n",
    "- No. of classes in train data = 22\n",
    "- Total Classes = 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### api\n",
    "\n",
    "- key: text\n",
    "- output1: class prediction\n",
    "- output2: probability of each class (higher is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=[\"I was asked to test a saal photobook and I was so delighted with the result! It arrived with in 10 days and was of such high quality, with a white leather look cover and an acrylic glass to protect the front photo. It has made a lovely lockdown gift for my best friend.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.130298</td>\n",
       "      <td>-0.10718</td>\n",
       "      <td>-0.263207</td>\n",
       "      <td>-0.112456</td>\n",
       "      <td>0.150111</td>\n",
       "      <td>-0.073012</td>\n",
       "      <td>-0.06689</td>\n",
       "      <td>-0.129732</td>\n",
       "      <td>-0.109085</td>\n",
       "      <td>0.201318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239544</td>\n",
       "      <td>0.044957</td>\n",
       "      <td>0.216894</td>\n",
       "      <td>-0.271231</td>\n",
       "      <td>0.088904</td>\n",
       "      <td>0.121324</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.115125</td>\n",
       "      <td>0.033772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0        1         2         3         4         5        6    \\\n",
       "0 -0.130298 -0.10718 -0.263207 -0.112456  0.150111 -0.073012 -0.06689   \n",
       "\n",
       "        7         8         9    ...       190       191       192       193  \\\n",
       "0 -0.129732 -0.109085  0.201318  ...  0.239544  0.044957  0.216894 -0.271231   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0  0.088904  0.121324  0.052762  0.001223  0.115125  0.033772  \n",
       "\n",
       "[1 rows x 200 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_arrays = np.zeros((len(texts), 200)) \n",
    "for i in range(len(texts)):\n",
    "    wordvec_arrays[i,:] = word_vector(texts[i], 200)\n",
    "    texts_df = pd.DataFrame(wordvec_arrays)\n",
    "texts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = loaded_model.predict_proba(texts_df)\n",
    "prediction_class = loaded_model.predict(texts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"['I was asked to test a saal photobook and I was so delighted with the result! It arrived with in 10 days and was of such high quality, with a white leather look cover and an acrylic glass to protect the front photo. It has made a lovely lockdown gift for my best friend.']\"\n",
      "  - Predicted as: '['Order management']'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\"{}\"'.format(texts))\n",
    "print(\"  - Predicted as: '{}'\".format(prediction_class))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer feedback</th>\n",
       "      <th>Data protection (Datenschutz)</th>\n",
       "      <th>Discovery voucher</th>\n",
       "      <th>Inkasso</th>\n",
       "      <th>Marketing</th>\n",
       "      <th>Musterbuch</th>\n",
       "      <th>Order management</th>\n",
       "      <th>Payment (Bezahlung)</th>\n",
       "      <th>Product (Produkt)</th>\n",
       "      <th>Production delays</th>\n",
       "      <th>...</th>\n",
       "      <th>Reseller workflow</th>\n",
       "      <th>Rücksendung</th>\n",
       "      <th>Samplebook-ProLine</th>\n",
       "      <th>ShareWithSaal</th>\n",
       "      <th>Shipping issues</th>\n",
       "      <th>Software/Webshop/App</th>\n",
       "      <th>Special conditions</th>\n",
       "      <th>product complaints - colours (Reklamation Farben)</th>\n",
       "      <th>product complaints - products (Reklamation Produkte)</th>\n",
       "      <th>product complaints - software (Reklamation Software)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.038072</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.007178</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.924992</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.00162</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.006769</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.00454</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.001511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer feedback  Data protection (Datenschutz)  Discovery voucher  \\\n",
       "0           0.000286                       0.038072           0.001403   \n",
       "\n",
       "    Inkasso  Marketing  Musterbuch  Order management  Payment (Bezahlung)  \\\n",
       "0  0.001161   0.007178    0.001681          0.924992             0.000775   \n",
       "\n",
       "   Product (Produkt)  Production delays  ...  Reseller workflow  Rücksendung  \\\n",
       "0            0.00162           0.000813  ...           0.001763     0.006769   \n",
       "\n",
       "   Samplebook-ProLine  ShareWithSaal  Shipping issues  Software/Webshop/App  \\\n",
       "0            0.000461       0.000994          0.00454              0.000512   \n",
       "\n",
       "   Special conditions  product complaints - colours (Reklamation Farben)  \\\n",
       "0            0.002329                                           0.000745   \n",
       "\n",
       "   product complaints - products (Reklamation Produkte)  \\\n",
       "0                                           0.000328      \n",
       "\n",
       "   product complaints - software (Reklamation Software)  \n",
       "0                                           0.001511     \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(loaded_model.predict_proba(texts_df), columns=loaded_model.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF NOTEBOOK CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
