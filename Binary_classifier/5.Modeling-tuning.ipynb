{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tunning\n",
    "\n",
    "We have already chosen best model. It's time to tune it and get best out of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)- Importing key modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#support both Python 2 and Python 3 with minimal overhead.\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re    # for regular expressions \n",
    "import nltk  # for text manipulation \n",
    "import string \n",
    "import numpy as np \n",
    "import pickle\n",
    "import pandas as pd \n",
    "\n",
    "#For Visuals\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 11, 8\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline\n",
    "\n",
    "# For model scores and tunning\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_curve,roc_auc_score,confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)- Loading Dataset & trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_pickle('file_clean.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-processed word2vec model\n",
    "\n",
    "from clean and vectorization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_df=pd.read_pickle('word2vec_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=wordvec_df\n",
    "y=data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8932, 200)\n",
      "(8932,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into training and validation set\n",
    "xtrain_word2vec, xvalid_word2vec, ytrain, yvalid = train_test_split(X, y,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7145, 200)\n",
      "(1787, 200)\n",
      "(7145,)\n",
      "(1787,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_word2vec.shape)\n",
    "print(xvalid_word2vec.shape)\n",
    "print(ytrain.shape)\n",
    "print(yvalid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.9391772e-01, 2.0608230e-01],\n",
       "       [4.2826951e-02, 9.5717305e-01],\n",
       "       [3.2508373e-04, 9.9967492e-01],\n",
       "       ...,\n",
       "       [9.8542094e-01, 1.4579064e-02],\n",
       "       [6.4736211e-01, 3.5263789e-01],\n",
       "       [9.9662358e-01, 3.3764120e-03]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = loaded_model.predict_proba(xvalid_word2vec)\n",
    "prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for standard threshold 0.5\n",
    "prediction_class = prediction[:,1] >= 0.5\n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_class.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.817011751538892"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.819436775262286"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.81      0.81       889\n",
      "         1.0       0.81      0.83      0.82       898\n",
      "\n",
      "    accuracy                           0.82      1787\n",
      "   macro avg       0.82      0.82      0.82      1787\n",
      "weighted avg       0.82      0.82      0.82      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, ..., False,  True, False])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for threshold 0.5\n",
    "\n",
    "prediction_class = prediction[:,1] >= 0.3\n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_class.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8047006155567991"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.815636555731643"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.75      0.79       889\n",
      "         1.0       0.78      0.86      0.82       898\n",
      "\n",
      "    accuracy                           0.80      1787\n",
      "   macro avg       0.81      0.80      0.80      1787\n",
      "weighted avg       0.81      0.80      0.80      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) FineTuning XGBoost + Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1)- Creating DMatrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use DMatrices. A DMatrix can contain both the features and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(xtrain_word2vec, label=ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvalid = xgb.DMatrix(xvalid_word2vec, label=yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters that we are going to tune \n",
    "params = {\n",
    "    'objective':'binary:logistic',\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2)- Scoring matric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have chosen vectorization method(word2vec), model(XGBoost) and it's time to choose evaluation matrix i.e f1=score as it is a binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_eval(preds, dtrain):\n",
    "    labels = dtrain.get_label().astype(np.int)\n",
    "    preds = (preds >= 0.3).astype(np.int)\n",
    "    return [('f1_score', f1_score(labels, preds))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4)- GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Approach for Parameter Tuning\n",
    "\n",
    "- Choose a relatively high learning rate. Usually a learning rate of 0.3 is used at this stage.\n",
    "- Tune tree-specific parameters such as max_depth, min_child_weight, subsample, colsample_bytree keeping the learning rate fixed.\n",
    "- Tune the learning rate.\n",
    "- Finally tune gamma to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1)- Tuning max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=6, min_child_weight=5\n",
      "CV with max_depth=6, min_child_weight=6\n",
      "CV with max_depth=6, min_child_weight=7\n",
      "CV with max_depth=7, min_child_weight=5\n",
      "CV with max_depth=7, min_child_weight=6\n",
      "CV with max_depth=7, min_child_weight=7\n",
      "CV with max_depth=8, min_child_weight=5\n",
      "CV with max_depth=8, min_child_weight=6\n",
      "CV with max_depth=8, min_child_weight=7\n",
      "CV with max_depth=9, min_child_weight=5\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\tF1 Score 0.8032527999999999 for 123 rounds\n",
      "Best params: 9, 7, F1 Score: 0.8032527999999999\n"
     ]
    }
   ],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(6,10)\n",
    "     for min_child_weight in range(5,8)\n",
    " ]\n",
    "max_f1 = 0. # initializing with 0 \n",
    "best_params = None \n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "\n",
    "# Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "\n",
    "    \n",
    "# Cross-validation\n",
    "    cv_results = xgb.cv(        params,\n",
    "        dtrain,        feval= custom_eval,\n",
    "        num_boost_round=200,\n",
    "        maximize=True,\n",
    "        seed=16,\n",
    "        nfold=5,\n",
    "        early_stopping_rounds=10\n",
    "    )    \n",
    "    \n",
    "# Finding best F1 Score\n",
    "    \n",
    "mean_f1 = cv_results['test-f1_score-mean'].max()\n",
    "\n",
    "boost_rounds = cv_results['test-f1_score-mean'].idxmax() \n",
    "\n",
    "print(\"\\tF1 Score {} for {} rounds\".format(mean_f1, boost_rounds))\n",
    "\n",
    "if mean_f1 > max_f1:\n",
    "        max_f1 = mean_f1\n",
    "        best_params = (max_depth,min_child_weight) \n",
    "        \n",
    "print(\"Best params: {}, {}, F1 Score: {}\".format(best_params[0], best_params[1], max_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Updating max_depth and min_child_weight parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 9 \n",
    "params['min_child_weight'] = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2)-Tuning subsample and colsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=0.5, colsample=0.5\n",
      "\tF1 Score 0.7889358000000001 for 88 rounds\n",
      "CV with subsample=0.5, colsample=0.6\n",
      "\tF1 Score 0.7889358000000001 for 88 rounds\n",
      "CV with subsample=0.5, colsample=0.7\n",
      "\tF1 Score 0.7889358000000001 for 88 rounds\n",
      "CV with subsample=0.5, colsample=0.8\n",
      "\tF1 Score 0.7889358000000001 for 88 rounds\n",
      "CV with subsample=0.5, colsample=0.9\n",
      "\tF1 Score 0.7889358000000001 for 88 rounds\n",
      "CV with subsample=0.6, colsample=0.5\n",
      "\tF1 Score 0.7918453999999999 for 78 rounds\n",
      "CV with subsample=0.6, colsample=0.6\n",
      "\tF1 Score 0.7918453999999999 for 78 rounds\n",
      "CV with subsample=0.6, colsample=0.7\n",
      "\tF1 Score 0.7918453999999999 for 78 rounds\n",
      "CV with subsample=0.6, colsample=0.8\n",
      "\tF1 Score 0.7918453999999999 for 78 rounds\n",
      "CV with subsample=0.6, colsample=0.9\n",
      "\tF1 Score 0.7918453999999999 for 78 rounds\n",
      "CV with subsample=0.7, colsample=0.5\n",
      "\tF1 Score 0.78279 for 43 rounds\n",
      "CV with subsample=0.7, colsample=0.6\n",
      "\tF1 Score 0.78279 for 43 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tF1 Score 0.78279 for 43 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tF1 Score 0.78279 for 43 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tF1 Score 0.78279 for 43 rounds\n",
      "CV with subsample=0.8, colsample=0.5\n",
      "\tF1 Score 0.7867664 for 50 rounds\n",
      "CV with subsample=0.8, colsample=0.6\n",
      "\tF1 Score 0.7867664 for 50 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tF1 Score 0.7867664 for 50 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tF1 Score 0.7867664 for 50 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tF1 Score 0.7867664 for 50 rounds\n",
      "CV with subsample=0.9, colsample=0.5\n",
      "\tF1 Score 0.7923882 for 93 rounds\n",
      "CV with subsample=0.9, colsample=0.6\n",
      "\tF1 Score 0.7923882 for 93 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tF1 Score 0.7923882 for 93 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tF1 Score 0.7923882 for 93 rounds\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tF1 Score 0.7923882 for 93 rounds\n",
      "Best params: 0.9, 0.5, F1 Score: 0.7923882\n"
     ]
    }
   ],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(5,10)]\n",
    "    for colsample in [i/10. for i in range(5,10)] ]\n",
    "max_f1 = 0. \n",
    "best_params = None \n",
    "for subsample, colsample in gridsearch_params:\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # Update our parameters\n",
    "    params['colsample'] = colsample\n",
    "    params['subsample'] = subsample\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        feval= custom_eval,\n",
    "        num_boost_round=200,\n",
    "        maximize=True,\n",
    "        seed=16,\n",
    "        nfold=5,\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "     # Finding best F1 Score\n",
    "    mean_f1 = cv_results['test-f1_score-mean'].max()\n",
    "    boost_rounds = cv_results['test-f1_score-mean'].idxmax()\n",
    "    print(\"\\tF1 Score {} for {} rounds\".format(mean_f1, boost_rounds))\n",
    "    if mean_f1 > max_f1:\n",
    "        max_f1 = mean_f1\n",
    "        best_params = (subsample, colsample) \n",
    "\n",
    "print(\"Best params: {}, {}, F1 Score: {}\".format(best_params[0], best_params[1], max_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = .9 \n",
    "params['colsample_bytree'] = .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3)- tune the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with eta=0.3\n",
      "\tF1 Score 0.8021998 for 107 rounds\n",
      "CV with eta=0.2\n",
      "\tF1 Score 0.8037496000000001 for 229 rounds\n",
      "CV with eta=0.1\n",
      "\tF1 Score 0.7991820000000001 for 136 rounds\n",
      "CV with eta=0.05\n",
      "\tF1 Score 0.7924262000000001 for 168 rounds\n",
      "CV with eta=0.01\n",
      "\tF1 Score 0.6751199999999999 for 0 rounds\n",
      "CV with eta=0.005\n",
      "\tF1 Score 0.6751199999999999 for 0 rounds\n",
      "Best params: 0.2, F1 Score: 0.8037496000000001\n"
     ]
    }
   ],
   "source": [
    "max_f1 = 0. \n",
    "best_params = None \n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "     # Update ETA\n",
    "    params['eta'] = eta\n",
    "\n",
    "     # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        feval= custom_eval,\n",
    "        num_boost_round=1000,\n",
    "        maximize=True,\n",
    "        seed=16,\n",
    "        nfold=5,\n",
    "        early_stopping_rounds=20\n",
    "    )\n",
    "\n",
    "     # Finding best F1 Score\n",
    "    mean_f1 = cv_results['test-f1_score-mean'].max()\n",
    "    boost_rounds = cv_results['test-f1_score-mean'].idxmax()\n",
    "    print(\"\\tF1 Score {} for {} rounds\".format(mean_f1, boost_rounds))\n",
    "    if mean_f1 > max_f1:\n",
    "        max_f1 = mean_f1\n",
    "        best_params = eta \n",
    "print(\"Best params: {}, F1 Score: {}\".format(best_params, max_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eta'] = .2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4)- List of tunned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample': 0.9,\n",
       " 'colsample_bytree': 0.5,\n",
       " 'eta': 0.2,\n",
       " 'max_depth': 9,\n",
       " 'min_child_weight': 7,\n",
       " 'objective': 'binary:logistic',\n",
       " 'subsample': 0.9}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params\n",
    "{'colsample': 0.9,\n",
    " 'colsample_bytree': 0.5, 'eta': 0.2,\n",
    " 'max_depth': 9, 'min_child_weight': 7,\n",
    " 'objective': 'binary:logistic',\n",
    " 'subsample': 0.9}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5)- Train the Tunned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tValidation-error:0.341354\tValidation-f1_score:0.668901\n",
      "Multiple eval metrics have been passed: 'Validation-f1_score' will be used for early stopping.\n",
      "\n",
      "Will train until Validation-f1_score hasn't improved in 10 rounds.\n",
      "[1]\tValidation-error:0.31953\tValidation-f1_score:0.668901\n",
      "[2]\tValidation-error:0.298825\tValidation-f1_score:0.684231\n",
      "[3]\tValidation-error:0.283156\tValidation-f1_score:0.699686\n",
      "[4]\tValidation-error:0.278679\tValidation-f1_score:0.709884\n",
      "[5]\tValidation-error:0.270285\tValidation-f1_score:0.716564\n",
      "[6]\tValidation-error:0.26413\tValidation-f1_score:0.728792\n",
      "[7]\tValidation-error:0.254617\tValidation-f1_score:0.733192\n",
      "[8]\tValidation-error:0.253497\tValidation-f1_score:0.733819\n",
      "[9]\tValidation-error:0.255176\tValidation-f1_score:0.732189\n",
      "[10]\tValidation-error:0.247902\tValidation-f1_score:0.740773\n",
      "[11]\tValidation-error:0.243984\tValidation-f1_score:0.745837\n",
      "[12]\tValidation-error:0.245104\tValidation-f1_score:0.751103\n",
      "[13]\tValidation-error:0.247342\tValidation-f1_score:0.757402\n",
      "[14]\tValidation-error:0.238948\tValidation-f1_score:0.757603\n",
      "[15]\tValidation-error:0.242865\tValidation-f1_score:0.756976\n",
      "[16]\tValidation-error:0.23559\tValidation-f1_score:0.759494\n",
      "[17]\tValidation-error:0.231114\tValidation-f1_score:0.763984\n",
      "[18]\tValidation-error:0.227196\tValidation-f1_score:0.761078\n",
      "[19]\tValidation-error:0.231114\tValidation-f1_score:0.759124\n",
      "[20]\tValidation-error:0.228875\tValidation-f1_score:0.764004\n",
      "[21]\tValidation-error:0.228875\tValidation-f1_score:0.764138\n",
      "[22]\tValidation-error:0.229435\tValidation-f1_score:0.76639\n",
      "[23]\tValidation-error:0.22216\tValidation-f1_score:0.769444\n",
      "[24]\tValidation-error:0.221041\tValidation-f1_score:0.770515\n",
      "[25]\tValidation-error:0.223279\tValidation-f1_score:0.771163\n",
      "[26]\tValidation-error:0.224958\tValidation-f1_score:0.772472\n",
      "[27]\tValidation-error:0.217683\tValidation-f1_score:0.773346\n",
      "[28]\tValidation-error:0.221041\tValidation-f1_score:0.776204\n",
      "[29]\tValidation-error:0.22216\tValidation-f1_score:0.782155\n",
      "[30]\tValidation-error:0.219362\tValidation-f1_score:0.780673\n",
      "[31]\tValidation-error:0.217683\tValidation-f1_score:0.781533\n",
      "[32]\tValidation-error:0.214885\tValidation-f1_score:0.782443\n",
      "[33]\tValidation-error:0.209849\tValidation-f1_score:0.785646\n",
      "[34]\tValidation-error:0.209849\tValidation-f1_score:0.783693\n",
      "[35]\tValidation-error:0.212087\tValidation-f1_score:0.7863\n",
      "[36]\tValidation-error:0.209289\tValidation-f1_score:0.787028\n",
      "[37]\tValidation-error:0.210968\tValidation-f1_score:0.788173\n",
      "[38]\tValidation-error:0.206491\tValidation-f1_score:0.783535\n",
      "[39]\tValidation-error:0.209289\tValidation-f1_score:0.783876\n",
      "[40]\tValidation-error:0.205932\tValidation-f1_score:0.786341\n",
      "[41]\tValidation-error:0.202574\tValidation-f1_score:0.782313\n",
      "[42]\tValidation-error:0.201455\tValidation-f1_score:0.783836\n",
      "[43]\tValidation-error:0.203693\tValidation-f1_score:0.78227\n",
      "[44]\tValidation-error:0.202015\tValidation-f1_score:0.784008\n",
      "[45]\tValidation-error:0.203693\tValidation-f1_score:0.783586\n",
      "[46]\tValidation-error:0.199776\tValidation-f1_score:0.785714\n",
      "[47]\tValidation-error:0.204253\tValidation-f1_score:0.781587\n",
      "Stopping. Best iteration:\n",
      "[37]\tValidation-error:0.210968\tValidation-f1_score:0.788173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    feval= custom_eval,\n",
    "    num_boost_round= 1000,\n",
    "    maximize=True,\n",
    "    evals=[(dvalid, \"Validation\")],\n",
    "    early_stopping_rounds=10\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This xgb_model can be tested on test set or out of sample data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
