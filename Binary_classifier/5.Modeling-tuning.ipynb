{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)- Importing key modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#support both Python 2 and Python 3 with minimal overhead.\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re    # for regular expressions \n",
    "import nltk  # for text manipulation \n",
    "import string \n",
    "import numpy as np \n",
    "import pickle\n",
    "import pandas as pd \n",
    "\n",
    "#For Visuals\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 11, 8\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline\n",
    "\n",
    "# For model scores and tunning\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_curve,roc_auc_score,confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)- Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_pickle('file_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8932, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>clean</th>\n",
       "      <th>clean2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Supplier shall update the Documentation on a r...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Supplier shall update the Documentation on a r...</td>\n",
       "      <td>supplier shall update documentation regular ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>major release upgrades of Software, change of ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>major release upgrade of Software change of Eq...</td>\n",
       "      <td>major release upgrade software change equipmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Accept incident severity as set by E.ON Servic...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Accept incident severity a set by E ON Service...</td>\n",
       "      <td>accept incident severity set e service desk ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Supplier shall provide all tools, documentatio...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Supplier shall provide all tool documentation ...</td>\n",
       "      <td>supplier shall provide tool documentation mate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>For smaller Projects a deviation can be agreed...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>For smaller Projects a deviation can be agreed...</td>\n",
       "      <td>smaller project deviation agreed within projec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class  \\\n",
       "0  Supplier shall update the Documentation on a r...    1.0   \n",
       "1  major release upgrades of Software, change of ...    1.0   \n",
       "2  Accept incident severity as set by E.ON Servic...    1.0   \n",
       "3  Supplier shall provide all tools, documentatio...    1.0   \n",
       "4  For smaller Projects a deviation can be agreed...    1.0   \n",
       "\n",
       "                                               clean  \\\n",
       "0  Supplier shall update the Documentation on a r...   \n",
       "1  major release upgrade of Software change of Eq...   \n",
       "2  Accept incident severity a set by E ON Service...   \n",
       "3  Supplier shall provide all tool documentation ...   \n",
       "4  For smaller Projects a deviation can be agreed...   \n",
       "\n",
       "                                              clean2  \n",
       "0  supplier shall update documentation regular ba...  \n",
       "1  major release upgrade software change equipmen...  \n",
       "2  accept incident severity set e service desk ce...  \n",
       "3  supplier shall provide tool documentation mate...  \n",
       "4  smaller project deviation agreed within projec...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)-Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-processed files \n",
    "\n",
    "from clean and vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_df=pd.read_pickle('word2vec_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=wordvec_df\n",
    "y=data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8932, 200)\n",
      "(8932,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into training and validation set\n",
    "xtrain_word2vec, xvalid_word2vec, ytrain, yvalid = train_test_split(X, y,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7145, 200)\n",
      "(1787, 200)\n",
      "(7145,)\n",
      "(1787,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_word2vec.shape)\n",
    "print(xvalid_word2vec.shape)\n",
    "print(ytrain.shape)\n",
    "print(yvalid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.9391772e-01, 2.0608230e-01],\n",
       "       [4.2826951e-02, 9.5717305e-01],\n",
       "       [3.2508373e-04, 9.9967492e-01],\n",
       "       ...,\n",
       "       [9.8542094e-01, 1.4579064e-02],\n",
       "       [6.4736211e-01, 3.5263789e-01],\n",
       "       [9.9662358e-01, 3.3764120e-03]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = loaded_model.predict_proba(xvalid_word2vec)\n",
    "prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for standard threshold 0.5\n",
    "prediction_class = prediction[:,1] >= 0.5\n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_class.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.817011751538892"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.819436775262286"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.81      0.81       889\n",
      "         1.0       0.81      0.83      0.82       898\n",
      "\n",
      "    accuracy                           0.82      1787\n",
      "   macro avg       0.82      0.82      0.82      1787\n",
      "weighted avg       0.82      0.82      0.82      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, ..., False,  True, False])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for threshold 0.5\n",
    "\n",
    "prediction_class = prediction[:,1] >= 0.3\n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_class.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8047006155567991"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.815636555731643"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.75      0.79       889\n",
      "         1.0       0.78      0.86      0.82       898\n",
      "\n",
      "    accuracy                           0.80      1787\n",
      "   macro avg       0.81      0.80      0.80      1787\n",
      "weighted avg       0.81      0.80      0.80      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) FineTuning XGBoost + Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1)- Creating DMatrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use DMatrices. A DMatrix can contain both the features and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(xtrain_word2vec, label=ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvalid = xgb.DMatrix(xvalid_word2vec, label=yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters that we are going to tune \n",
    "params = {\n",
    "    'objective':'binary:logistic',\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2)- Scoring matric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have chosen vectorization method(word2vec), model(XGBoost) and it's time to choose evaluation matrix i.e f1=score as it is a binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_eval(preds, dtrain):\n",
    "    labels = dtrain.get_label().astype(np.int)\n",
    "    preds = (preds >= 0.3).astype(np.int)\n",
    "    return [('f1_score', f1_score(labels, preds))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4)- GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Approach for Parameter Tuning\n",
    "\n",
    "- Choose a relatively high learning rate. Usually a learning rate of 0.3 is used at this stage.\n",
    "- Tune tree-specific parameters such as max_depth, min_child_weight, subsample, colsample_bytree keeping the learning rate fixed.\n",
    "- Tune the learning rate.\n",
    "- Finally tune gamma to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1)- Tuning max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=6, min_child_weight=5\n",
      "CV with max_depth=6, min_child_weight=6\n",
      "CV with max_depth=6, min_child_weight=7\n",
      "CV with max_depth=7, min_child_weight=5\n",
      "CV with max_depth=7, min_child_weight=6\n",
      "CV with max_depth=7, min_child_weight=7\n",
      "CV with max_depth=8, min_child_weight=5\n",
      "CV with max_depth=8, min_child_weight=6\n",
      "CV with max_depth=8, min_child_weight=7\n",
      "CV with max_depth=9, min_child_weight=5\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\tF1 Score 0.8032527999999999 for 123 rounds\n",
      "Best params: 9, 7, F1 Score: 0.8032527999999999\n"
     ]
    }
   ],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(6,10)\n",
    "     for min_child_weight in range(5,8)\n",
    " ]\n",
    "max_f1 = 0. # initializing with 0 \n",
    "best_params = None \n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "\n",
    "# Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "\n",
    "    \n",
    "# Cross-validation\n",
    "    cv_results = xgb.cv(        params,\n",
    "        dtrain,        feval= custom_eval,\n",
    "        num_boost_round=200,\n",
    "        maximize=True,\n",
    "        seed=16,\n",
    "        nfold=5,\n",
    "        early_stopping_rounds=10\n",
    "    )    \n",
    "    \n",
    "# Finding best F1 Score\n",
    "    \n",
    "mean_f1 = cv_results['test-f1_score-mean'].max()\n",
    "\n",
    "boost_rounds = cv_results['test-f1_score-mean'].idxmax() \n",
    "\n",
    "print(\"\\tF1 Score {} for {} rounds\".format(mean_f1, boost_rounds))\n",
    "\n",
    "if mean_f1 > max_f1:\n",
    "        max_f1 = mean_f1\n",
    "        best_params = (max_depth,min_child_weight) \n",
    "        \n",
    "print(\"Best params: {}, {}, F1 Score: {}\".format(best_params[0], best_params[1], max_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Updating max_depth and min_child_weight parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 9 \n",
    "params['min_child_weight'] = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2)-Tuning subsample and colsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=0.5, colsample=0.5\n",
      "\tF1 Score 0.7889358000000001 for 88 rounds\n",
      "CV with subsample=0.5, colsample=0.6\n",
      "\tF1 Score 0.7889358000000001 for 88 rounds\n",
      "CV with subsample=0.5, colsample=0.7\n",
      "\tF1 Score 0.7889358000000001 for 88 rounds\n",
      "CV with subsample=0.5, colsample=0.8\n",
      "\tF1 Score 0.7889358000000001 for 88 rounds\n",
      "CV with subsample=0.5, colsample=0.9\n",
      "\tF1 Score 0.7889358000000001 for 88 rounds\n",
      "CV with subsample=0.6, colsample=0.5\n",
      "\tF1 Score 0.7918453999999999 for 78 rounds\n",
      "CV with subsample=0.6, colsample=0.6\n"
     ]
    }
   ],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(5,10)]\n",
    "    for colsample in [i/10. for i in range(5,10)] ]\n",
    "max_f1 = 0. \n",
    "best_params = None \n",
    "for subsample, colsample in gridsearch_params:\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # Update our parameters\n",
    "    params['colsample'] = colsample\n",
    "    params['subsample'] = subsample\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        feval= custom_eval,\n",
    "        num_boost_round=200,\n",
    "        maximize=True,\n",
    "        seed=16,\n",
    "        nfold=5,\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "     # Finding best F1 Score\n",
    "    mean_f1 = cv_results['test-f1_score-mean'].max()\n",
    "    boost_rounds = cv_results['test-f1_score-mean'].idxmax()\n",
    "    print(\"\\tF1 Score {} for {} rounds\".format(mean_f1, boost_rounds))\n",
    "    if mean_f1 > max_f1:\n",
    "        max_f1 = mean_f1\n",
    "        best_params = (subsample, colsample) \n",
    "\n",
    "print(\"Best params: {}, {}, F1 Score: {}\".format(best_params[0], best_params[1], max_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = .9 \n",
    "params['colsample_bytree'] = .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3)- tune the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_f1 = 0. \n",
    "best_params = None \n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "     # Update ETA\n",
    "    params['eta'] = eta\n",
    "\n",
    "     # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        feval= custom_eval,\n",
    "        num_boost_round=1000,\n",
    "        maximize=True,\n",
    "        seed=16,\n",
    "        nfold=5,\n",
    "        early_stopping_rounds=20\n",
    "    )\n",
    "\n",
    "     # Finding best F1 Score\n",
    "    mean_f1 = cv_results['test-f1_score-mean'].max()\n",
    "    boost_rounds = cv_results['test-f1_score-mean'].idxmax()\n",
    "    print(\"\\tF1 Score {} for {} rounds\".format(mean_f1, boost_rounds))\n",
    "    if mean_f1 > max_f1:\n",
    "        max_f1 = mean_f1\n",
    "        best_params = eta \n",
    "print(\"Best params: {}, F1 Score: {}\".format(best_params, max_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eta'] = .2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4)- List of tunned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params\n",
    "{'colsample': 0.9,\n",
    " 'colsample_bytree': 0.5, 'eta': 0.2,\n",
    " 'max_depth': 9, 'min_child_weight': 7,\n",
    " 'objective': 'binary:logistic',\n",
    " 'subsample': 0.9}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5)- Train the Tunned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    feval= custom_eval,\n",
    "    num_boost_round= 1000,\n",
    "    maximize=True,\n",
    "    evals=[(dvalid, \"Validation\")],\n",
    "    early_stopping_rounds=10\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
