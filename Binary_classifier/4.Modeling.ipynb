{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Before modeling, there will be EDA, Cleaning and vectorization procedures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)- Importing key modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#support both Python 2 and Python 3 with minimal overhead.\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re    # for regular expressions \n",
    "import nltk  # for text manipulation \n",
    "import string \n",
    "import numpy as np \n",
    "import pickle\n",
    "import pandas as pd \n",
    "\n",
    "#For Visuals\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 11, 8\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)- Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_pickle('file_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8932, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>clean</th>\n",
       "      <th>clean2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Supplier shall update the Documentation on a r...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Supplier shall update the Documentation on a r...</td>\n",
       "      <td>supplier shall update documentation regular ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>major release upgrades of Software, change of ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>major release upgrade of Software change of Eq...</td>\n",
       "      <td>major release upgrade software change equipmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Accept incident severity as set by E.ON Servic...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Accept incident severity a set by E ON Service...</td>\n",
       "      <td>accept incident severity set e service desk ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Supplier shall provide all tools, documentatio...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Supplier shall provide all tool documentation ...</td>\n",
       "      <td>supplier shall provide tool documentation mate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>For smaller Projects a deviation can be agreed...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>For smaller Projects a deviation can be agreed...</td>\n",
       "      <td>smaller project deviation agreed within projec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class  \\\n",
       "0  Supplier shall update the Documentation on a r...    1.0   \n",
       "1  major release upgrades of Software, change of ...    1.0   \n",
       "2  Accept incident severity as set by E.ON Servic...    1.0   \n",
       "3  Supplier shall provide all tools, documentatio...    1.0   \n",
       "4  For smaller Projects a deviation can be agreed...    1.0   \n",
       "\n",
       "                                               clean  \\\n",
       "0  Supplier shall update the Documentation on a r...   \n",
       "1  major release upgrade of Software change of Eq...   \n",
       "2  Accept incident severity a set by E ON Service...   \n",
       "3  Supplier shall provide all tool documentation ...   \n",
       "4  For smaller Projects a deviation can be agreed...   \n",
       "\n",
       "                                              clean2  \n",
       "0  supplier shall update documentation regular ba...  \n",
       "1  major release upgrade software change equipmen...  \n",
       "2  accept incident severity set e service desk ce...  \n",
       "3  supplier shall provide tool documentation mate...  \n",
       "4  smaller project deviation agreed within projec...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>clean</th>\n",
       "      <th>clean2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8927</td>\n",
       "      <td>EnsurethatSupplier’sperformancerequirementsast...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EnsurethatSupplier sperformancerequirementsast...</td>\n",
       "      <td>ensurethatsupplier sperformancerequirementsast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8928</td>\n",
       "      <td>Establishandexecutetheaccountmanagementdiscipl...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Establishandexecutetheaccountmanagementdiscipl...</td>\n",
       "      <td>establishandexecutetheaccountmanagementdiscipl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8929</td>\n",
       "      <td>Reviewofconsolidatedforecast/demandreportscove...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Reviewofconsolidatedforecast demandreportscove...</td>\n",
       "      <td>reviewofconsolidatedforecast demandreportscove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8930</td>\n",
       "      <td>OnceE.ON'sContractManagerdecidestoproceedwitha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>OnceE ON sContractManagerdecidestoproceedwitha...</td>\n",
       "      <td>oncee scontractmanagerdecidestoproceedwithaccn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8931</td>\n",
       "      <td>maymaketemporaryOperationalChanges,incaseitisa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>maymaketemporaryOperationalChanges incaseitisa...</td>\n",
       "      <td>maymaketemporaryoperationalchanges incaseitisa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  class  \\\n",
       "8927  EnsurethatSupplier’sperformancerequirementsast...    0.0   \n",
       "8928  Establishandexecutetheaccountmanagementdiscipl...    0.0   \n",
       "8929  Reviewofconsolidatedforecast/demandreportscove...    0.0   \n",
       "8930  OnceE.ON'sContractManagerdecidestoproceedwitha...    0.0   \n",
       "8931  maymaketemporaryOperationalChanges,incaseitisa...    0.0   \n",
       "\n",
       "                                                  clean  \\\n",
       "8927  EnsurethatSupplier sperformancerequirementsast...   \n",
       "8928  Establishandexecutetheaccountmanagementdiscipl...   \n",
       "8929  Reviewofconsolidatedforecast demandreportscove...   \n",
       "8930  OnceE ON sContractManagerdecidestoproceedwitha...   \n",
       "8931  maymaketemporaryOperationalChanges incaseitisa...   \n",
       "\n",
       "                                                 clean2  \n",
       "8927  ensurethatsupplier sperformancerequirementsast...  \n",
       "8928  establishandexecutetheaccountmanagementdiscipl...  \n",
       "8929  reviewofconsolidatedforecast demandreportscove...  \n",
       "8930  oncee scontractmanagerdecidestoproceedwithaccn...  \n",
       "8931  maymaketemporaryoperationalchanges incaseitisa...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    4539\n",
       "0.0    4393\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0 means other text and 1 means Deliverable and Obligations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3)- Model\n",
    "\n",
    "- Logistic Regression\n",
    "- Support Vector Machine\n",
    "- Naives Bayes\n",
    "- RandomForest\n",
    "- XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pickle files before we start training\n",
    "\n",
    "bow=pd.read_pickle('bow_model.pkl')\n",
    "tfidf=pd.read_pickle('tfidf_model.pkl')\n",
    "wordvec_df=pd.read_pickle('word2vec_model.pkl')\n",
    "docvec_df=pd.read_pickle('doc2vec_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1)- Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_curve,roc_auc_score,confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Logistic Regression using Bag-of-Words Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=bow\n",
    "y=data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8932, 1000)\n",
      "(8932,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into training and validation set\n",
    "xtrain_bow, xvalid_bow, ytrain, yvalid = train_test_split(bow, y,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7145, 1000)\n",
      "(1787, 1000)\n",
      "(7145,)\n",
      "(1787,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_bow.shape)\n",
    "print(xvalid_bow.shape)\n",
    "print(ytrain.shape)\n",
    "print(yvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# training the model\n",
    "lreg.fit(xtrain_bow, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57070774, 0.42929226],\n",
       "       [0.06826315, 0.93173685],\n",
       "       [0.05078176, 0.94921824],\n",
       "       ...,\n",
       "       [0.75704973, 0.24295027],\n",
       "       [0.894826  , 0.105174  ],\n",
       "       [0.97484251, 0.02515749]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting on the validation set\n",
    "prediction = lreg.predict_proba(xvalid_bow)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction over classes\n",
    "\n",
    "prediction_class=lreg.predict(xvalid_bow)\n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8030218242865137"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803208479786352"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(yvalid, prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[747, 142],\n",
       "       [210, 688]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yvalid, prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.84      0.81       889\n",
      "         1.0       0.83      0.77      0.80       898\n",
      "\n",
      "    accuracy                           0.80      1787\n",
      "   macro avg       0.80      0.80      0.80      1787\n",
      "weighted avg       0.80      0.80      0.80      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Changing threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if prediction is greater than or equal to 0.3 than 1 else 0\n",
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803680981595092"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating f1 score for the validation set\n",
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7851147174034695"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating accuracy score for the validation set\n",
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7846583208279366"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# roc-auc score\n",
    "roc_auc_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[617, 272],\n",
       "       [112, 786]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.69      0.76       889\n",
      "         1.0       0.74      0.88      0.80       898\n",
      "\n",
      "    accuracy                           0.79      1787\n",
      "   macro avg       0.79      0.78      0.78      1787\n",
      "weighted avg       0.79      0.79      0.78      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By changing threshold, we have seen a decrease in accuracy but, we have got more precise results for class 1 i.e O&B. So, it is trade-off between accuracy and precision.\n",
    "\n",
    "For this excercise, we are more interested in Class 1 precised results so, 0.3 threshold is used for rest of notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Logistic Regression using TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tfidf\n",
    "y=data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8932, 1000)\n",
      "(8932,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into training and validation set\n",
    "xtrain_tfidf, xvalid_tfidf, ytrain, yvalid = train_test_split(tfidf, y,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7145, 1000)\n",
      "(1787, 1000)\n",
      "(7145,)\n",
      "(1787,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_tfidf.shape)\n",
    "print(xvalid_tfidf.shape)\n",
    "print(ytrain.shape)\n",
    "print(yvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# training the model\n",
    "lreg.fit(xtrain_tfidf, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38226668, 0.61773332],\n",
       "       [0.1795822 , 0.8204178 ],\n",
       "       [0.12885721, 0.87114279],\n",
       "       ...,\n",
       "       [0.68508414, 0.31491586],\n",
       "       [0.6982247 , 0.3017753 ],\n",
       "       [0.90387319, 0.09612681]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting on the validation set\n",
    "prediction = lreg.predict_proba(xvalid_tfidf)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True, False])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same rule : if prediction is greater than or equal to 0.3 than 1 else 0\n",
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7336317851147174"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7806451612903227"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating f1 score for the validation set\n",
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[464, 425],\n",
       "       [ 51, 847]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.52      0.66       889\n",
      "         1.0       0.67      0.94      0.78       898\n",
      "\n",
      "    accuracy                           0.73      1787\n",
      "   macro avg       0.78      0.73      0.72      1787\n",
      "weighted avg       0.78      0.73      0.72      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Logistic Regression using Word2Vec Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=wordvec_df\n",
    "y=data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8932, 200)\n",
      "(8932,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into training and validation set\n",
    "xtrain_word2vec, xvalid_word2vec, ytrain, yvalid = train_test_split(X, y,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7145, 200)\n",
      "(1787, 200)\n",
      "(7145,)\n",
      "(1787,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_word2vec.shape)\n",
    "print(xvalid_word2vec.shape)\n",
    "print(ytrain.shape)\n",
    "print(yvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model\n",
    "lreg.fit(xtrain_word2vec, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36783016, 0.63216984],\n",
       "       [0.1183427 , 0.8816573 ],\n",
       "       [0.18988563, 0.81011437],\n",
       "       ...,\n",
       "       [0.56433758, 0.43566242],\n",
       "       [0.49043159, 0.50956841],\n",
       "       [0.76519438, 0.23480562]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting on the validation set\n",
    "prediction = lreg.predict_proba(xvalid_word2vec)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True, False])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7405146096816398"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6670397313933968"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[343, 546],\n",
       "       [ 49, 849]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.39      0.54       889\n",
      "         1.0       0.61      0.95      0.74       898\n",
      "\n",
      "    accuracy                           0.67      1787\n",
      "   macro avg       0.74      0.67      0.64      1787\n",
      "weighted avg       0.74      0.67      0.64      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4 Logistic Regression using Doc2Vec Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=docvec_df\n",
    "y=data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8932, 200)\n",
      "(8932,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into training and validation set\n",
    "xtrain_doc2vec, xvalid_doc2vec, ytrain, yvalid = train_test_split(X, y,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7145, 200)\n",
      "(1787, 200)\n",
      "(7145,)\n",
      "(1787,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_doc2vec.shape)\n",
    "print(xvalid_doc2vec.shape)\n",
    "print(ytrain.shape)\n",
    "print(yvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model\n",
    "lreg.fit(xtrain_doc2vec, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40029179, 0.59970821],\n",
       "       [0.15948637, 0.84051363],\n",
       "       [0.41839632, 0.58160368],\n",
       "       ...,\n",
       "       [0.66038584, 0.33961416],\n",
       "       [0.42146772, 0.57853228],\n",
       "       [0.12542656, 0.87457344]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting on the validation set\n",
    "prediction = lreg.predict_proba(xvalid_doc2vec)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7512551346417161"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6950195858981534"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[419, 470],\n",
       "       [ 75, 823]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.47      0.61       889\n",
      "         1.0       0.64      0.92      0.75       898\n",
      "\n",
      "    accuracy                           0.70      1787\n",
      "   macro avg       0.74      0.69      0.68      1787\n",
      "weighted avg       0.74      0.70      0.68      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a simpler dataset, bag of words is giving best score. Howver, we can see that tfidf and word2vec performs very well i.e 0.94 score for class 1 and very bad for class 0. So, we may use them if we are interested in more precise results for class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2)-Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 SVM using Bag-of-Words Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='linear', C=1, probability=True).fit(xtrain_bow, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62764233, 0.37235767],\n",
       "       [0.15052447, 0.84947553],\n",
       "       [0.15829892, 0.84170108],\n",
       "       ...,\n",
       "       [0.75634492, 0.24365508],\n",
       "       [0.83553348, 0.16446652],\n",
       "       [0.95204019, 0.04795981]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = svc.predict_proba(xvalid_bow)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7565752658086178"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.783689706613625"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[564, 325],\n",
       "       [110, 788]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.63      0.72       889\n",
      "         1.0       0.71      0.88      0.78       898\n",
      "\n",
      "    accuracy                           0.76      1787\n",
      "   macro avg       0.77      0.76      0.75      1787\n",
      "weighted avg       0.77      0.76      0.75      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 SVM using TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='linear',C=1, probability=True).fit(xtrain_tfidf, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42282726, 0.57717274],\n",
       "       [0.12759646, 0.87240354],\n",
       "       [0.05459321, 0.94540679],\n",
       "       ...,\n",
       "       [0.80396909, 0.19603091],\n",
       "       [0.85134327, 0.14865673],\n",
       "       [0.96904258, 0.03095742]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = svc.predict_proba(xvalid_tfidf)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7588136541689984"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7884143348060874"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[553, 336],\n",
       "       [ 95, 803]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.62      0.72       889\n",
      "         1.0       0.71      0.89      0.79       898\n",
      "\n",
      "    accuracy                           0.76      1787\n",
      "   macro avg       0.78      0.76      0.75      1787\n",
      "weighted avg       0.78      0.76      0.75      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 SVM using word2vec Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='linear', C=1, probability=True).fit(xtrain_word2vec, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48041304, 0.51958696],\n",
       "       [0.11418709, 0.88581291],\n",
       "       [0.20920935, 0.79079065],\n",
       "       ...,\n",
       "       [0.64110967, 0.35889033],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.77104888, 0.22895112]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = svc.predict_proba(xvalid_word2vec)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True, False])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.668158925573587"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7395696091348264"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[352 537]\n",
      " [ 56 842]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.40      0.54       889\n",
      "         1.0       0.61      0.94      0.74       898\n",
      "\n",
      "    accuracy                           0.67      1787\n",
      "   macro avg       0.74      0.67      0.64      1787\n",
      "weighted avg       0.74      0.67      0.64      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 SVM using doc2vec Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='linear', C=1, probability=True).fit(xtrain_doc2vec, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37773937, 0.62226063],\n",
       "       [0.1607062 , 0.8392938 ],\n",
       "       [0.43435575, 0.56564425],\n",
       "       ...,\n",
       "       [0.63707993, 0.36292007],\n",
       "       [0.40103994, 0.59896006],\n",
       "       [0.14039158, 0.85960842]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = svc.predict_proba(xvalid_doc2vec)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6804700615556799"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7445190156599553"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[384 505]\n",
      " [ 66 832]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.43      0.57       889\n",
      "         1.0       0.62      0.93      0.74       898\n",
      "\n",
      "    accuracy                           0.68      1787\n",
      "   macro avg       0.74      0.68      0.66      1787\n",
      "weighted avg       0.74      0.68      0.66      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3)- Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Naive Bayes using Bag-of-Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(xtrain_bow, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44420094, 0.55579906],\n",
       "       [0.03296167, 0.96703833],\n",
       "       [0.00234653, 0.99765347],\n",
       "       ...,\n",
       "       [0.72864983, 0.27135017],\n",
       "       [0.24624521, 0.75375479],\n",
       "       [0.98842928, 0.01157072]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# naive bayes in theory does not work well with predict_probab so, we shall use prediction directly\n",
    "prediction = mnb.predict_proba(xvalid_bow)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False,  True, False])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6793508673754897"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.727790973871734"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[448 441]\n",
      " [132 766]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.50      0.61       889\n",
      "         1.0       0.63      0.85      0.73       898\n",
      "\n",
      "    accuracy                           0.68      1787\n",
      "   macro avg       0.70      0.68      0.67      1787\n",
      "weighted avg       0.70      0.68      0.67      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Naive Bayes using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(xtrain_tfidf, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45332712, 0.54667288],\n",
       "       [0.31474078, 0.68525922],\n",
       "       [0.1394017 , 0.8605983 ],\n",
       "       ...,\n",
       "       [0.61807525, 0.38192475],\n",
       "       [0.42044278, 0.57955722],\n",
       "       [0.82730073, 0.17269927]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = mnb.predict_proba(xvalid_tfidf)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True, False])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6183547845551203"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7172470978441128"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[240 649]\n",
      " [ 33 865]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.27      0.41       889\n",
      "         1.0       0.57      0.96      0.72       898\n",
      "\n",
      "    accuracy                           0.62      1787\n",
      "   macro avg       0.73      0.62      0.57      1787\n",
      "weighted avg       0.72      0.62      0.57      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3 Naive Bayes using word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for Naive Bayes, Input X must be non-negative. In case of Word2vec and Doc2vec, Naive Bayes is not ideal. So we will not use it. It is not giving any exceptional results anyway.\n",
    "\n",
    "For results, we have already have better models' outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.4 Naive Bayes using doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1-RF with Bag-of-Words Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=400, random_state=11).fit(xtrain_bow, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74625   , 0.25375   ],\n",
       "       [0.3675    , 0.6325    ],\n",
       "       [0.0225    , 0.9775    ],\n",
       "       ...,\n",
       "       [0.73058333, 0.26941667],\n",
       "       [0.93833333, 0.06166667],\n",
       "       [1.        , 0.        ]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = rf.predict_proba(xvalid_bow)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.792360430950049"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7627308337996642"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[554 335]\n",
      " [ 89 809]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.62      0.72       889\n",
      "         1.0       0.71      0.90      0.79       898\n",
      "\n",
      "    accuracy                           0.76      1787\n",
      "   macro avg       0.78      0.76      0.76      1787\n",
      "weighted avg       0.78      0.76      0.76      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2-RF with TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=400, random_state=11).fit(xtrain_tfidf, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60333333, 0.39666667],\n",
       "       [0.38725   , 0.61275   ],\n",
       "       [0.0225    , 0.9775    ],\n",
       "       ...,\n",
       "       [0.91291667, 0.08708333],\n",
       "       [0.793125  , 0.206875  ],\n",
       "       [0.95791667, 0.04208333]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = rf.predict_proba(xvalid_tfidf)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7632904308897593"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7945604662457503"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[546 343]\n",
      " [ 80 818]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.61      0.72       889\n",
      "         1.0       0.70      0.91      0.79       898\n",
      "\n",
      "    accuracy                           0.76      1787\n",
      "   macro avg       0.79      0.76      0.76      1787\n",
      "weighted avg       0.79      0.76      0.76      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.3-RF with word2vec Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7145, 200)\n",
      "(1787, 200)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_word2vec.shape)\n",
    "print(xvalid_word2vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=400, random_state=11).fit(xtrain_word2vec, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52354167, 0.47645833],\n",
       "       [0.23291667, 0.76708333],\n",
       "       [0.12945833, 0.87054167],\n",
       "       ...,\n",
       "       [0.66191667, 0.33808333],\n",
       "       [0.485     , 0.515     ],\n",
       "       [0.79608333, 0.20391667]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction= rf.predict_proba(xvalid_word2vec)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True, False])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6385002797985451"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7229845626072041"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[298 591]\n",
      " [ 55 843]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.34      0.48       889\n",
      "         1.0       0.59      0.94      0.72       898\n",
      "\n",
      "    accuracy                           0.64      1787\n",
      "   macro avg       0.72      0.64      0.60      1787\n",
      "weighted avg       0.72      0.64      0.60      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.4-RF with doc2vec Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7145, 200)\n",
      "(1787, 200)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_doc2vec.shape)\n",
    "print(xvalid_doc2vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=400, random_state=11).fit(xtrain_doc2vec, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4   , 0.6   ],\n",
       "       [0.3225, 0.6775],\n",
       "       [0.455 , 0.545 ],\n",
       "       ...,\n",
       "       [0.5575, 0.4425],\n",
       "       [0.4   , 0.6   ],\n",
       "       [0.3525, 0.6475]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction= rf.predict_proba(xvalid_doc2vec)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6424174594292109"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7318506084767099"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[276 613]\n",
      " [ 26 872]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.31      0.46       889\n",
      "         1.0       0.59      0.97      0.73       898\n",
      "\n",
      "    accuracy                           0.64      1787\n",
      "   macro avg       0.75      0.64      0.60      1787\n",
      "weighted avg       0.75      0.64      0.60      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5)-XGBoost \n",
    "\n",
    "Extreme Gradient Boosting (xgboost) is an advanced implementation of gradient boosting algorithm. It has both linear model solver and tree learning algorithms. Its ability to do parallel computation on a single machine makes it extremely fast. It also has additional features for doing cross validation and finding important variables. There are many parameters which need to be controlled to optimize the model.\n",
    "\n",
    "Some key benefits of XGBoost are:\n",
    "\n",
    "- Regularization - helps in reducing overfitting\n",
    "- Parallel Processing - XGBoost implements parallel processing and is blazingly faster as compared to GBM.\n",
    "- Handling Missing Values - It has an in-built routine to handle missing values.\n",
    "- Built-in Cross-Validation - allows user to run a cross-validation at each iteration of the boosting process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.1) XGBoost using bag of words features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(max_depth=6, n_estimators=1000).fit(xtrain_bow, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6994201 , 0.3005799 ],\n",
       "       [0.16367435, 0.83632565],\n",
       "       [0.02237719, 0.9776228 ],\n",
       "       ...,\n",
       "       [0.89265764, 0.10734234],\n",
       "       [0.85022104, 0.14977898],\n",
       "       [0.9595621 , 0.04043785]], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = xgb_model.predict_proba(xvalid_bow)\n",
    "prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7912702853945159"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8097909229984702"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[620 269]\n",
      " [104 794]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.70      0.77       889\n",
      "         1.0       0.75      0.88      0.81       898\n",
      "\n",
      "    accuracy                           0.79      1787\n",
      "   macro avg       0.80      0.79      0.79      1787\n",
      "weighted avg       0.80      0.79      0.79      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.2) XGBoost using tfidffeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(max_depth=6, n_estimators=1000).fit(xtrain_tfidf, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3995415 , 0.6004585 ],\n",
       "       [0.40370852, 0.5962915 ],\n",
       "       [0.01535803, 0.98464197],\n",
       "       ...,\n",
       "       [0.9596097 , 0.0403903 ],\n",
       "       [0.8704996 , 0.12950037],\n",
       "       [0.9770459 , 0.02295412]], dtype=float32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = xgb_model.predict_proba(xvalid_tfidf)\n",
    "prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7806379406827084"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8012170385395536"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[605 284]\n",
      " [108 790]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.68      0.76       889\n",
      "         1.0       0.74      0.88      0.80       898\n",
      "\n",
      "    accuracy                           0.78      1787\n",
      "   macro avg       0.79      0.78      0.78      1787\n",
      "weighted avg       0.79      0.78      0.78      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.3) XGBoost using word2vecfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(max_depth=6, n_estimators=1000).fit(xtrain_word2vec, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.9391772e-01, 2.0608230e-01],\n",
       "       [4.2826951e-02, 9.5717305e-01],\n",
       "       [3.2508373e-04, 9.9967492e-01],\n",
       "       ...,\n",
       "       [9.8542094e-01, 1.4579064e-02],\n",
       "       [6.4736211e-01, 3.5263789e-01],\n",
       "       [9.9662358e-01, 3.3764120e-03]], dtype=float32)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = xgb_model.predict_proba(xvalid_word2vec)\n",
    "prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, ..., False,  True, False])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8047006155567991"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.815636555731643"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[666 223]\n",
      " [126 772]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.75      0.79       889\n",
      "         1.0       0.78      0.86      0.82       898\n",
      "\n",
      "    accuracy                           0.80      1787\n",
      "   macro avg       0.81      0.80      0.80      1787\n",
      "weighted avg       0.81      0.80      0.80      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.4) XGBoost using doc2vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(max_depth=6, n_estimators=1000).fit(xtrain_doc2vec, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53582823, 0.46417174],\n",
       "       [0.04373556, 0.95626444],\n",
       "       [0.3479312 , 0.6520688 ],\n",
       "       ...,\n",
       "       [0.9962422 , 0.00375777],\n",
       "       [0.03484458, 0.9651554 ],\n",
       "       [0.09240466, 0.90759534]], dtype=float32)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = xgb_model.predict_proba(xvalid_doc2vec)\n",
    "prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False,  True,  True])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction[:,1] >= 0.3\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7571348628987129"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792472024415055"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[587 302]\n",
      " [132 766]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.66      0.73       889\n",
      "         1.0       0.72      0.85      0.78       898\n",
      "\n",
      "    accuracy                           0.76      1787\n",
      "   macro avg       0.77      0.76      0.75      1787\n",
      "weighted avg       0.77      0.76      0.75      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost using word2vec gives us the best results with our given matrics shown in classification report in sect 6.5.3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_best = XGBClassifier(max_depth=6, n_estimators=1000).fit(xtrain_word2vec, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(xgb_model_best, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.9391772e-01, 2.0608230e-01],\n",
       "       [4.2826951e-02, 9.5717305e-01],\n",
       "       [3.2508373e-04, 9.9967492e-01],\n",
       "       ...,\n",
       "       [9.8542094e-01, 1.4579064e-02],\n",
       "       [6.4736211e-01, 3.5263789e-01],\n",
       "       [9.9662358e-01, 3.3764120e-03]], dtype=float32)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = loaded_model.predict_proba(xvalid_word2vec)\n",
    "prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for standard threshold 0.5\n",
    "prediction_class = prediction[:,1] >= 0.5\n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_class.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.817011751538892"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.819436775262286"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.81      0.81       889\n",
      "         1.0       0.81      0.83      0.82       898\n",
      "\n",
      "    accuracy                           0.82      1787\n",
      "   macro avg       0.82      0.82      0.82      1787\n",
      "weighted avg       0.82      0.82      0.82      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, ..., False,  True, False])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for threshold 0.5\n",
    "\n",
    "prediction_class = prediction[:,1] >= 0.3\n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_int = prediction_class.astype(np.int)\n",
    "prediction_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8047006155567991"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.815636555731643"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.75      0.79       889\n",
      "         1.0       0.78      0.86      0.82       898\n",
      "\n",
      "    accuracy                           0.80      1787\n",
      "   macro avg       0.81      0.80      0.80      1787\n",
      "weighted avg       0.81      0.80      0.80      1787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why XBBoost is most optimal model ?\n",
    "\n",
    "Reason is that it maintains a good score of accuracy and f1 for both levels of threshold i.e 0.3 and 0.5. Other models like Random Forest does not handle imbalance class very well. That's Boosting algorithms sometimes outperform ensemble learning methods and this is one of those examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
