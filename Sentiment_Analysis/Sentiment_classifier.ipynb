{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis using different ML and DL algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re, numpy as np, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\69785hsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ML algorithm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>candidate</th>\n",
       "      <th>candidate_confidence</th>\n",
       "      <th>relevant_yn</th>\n",
       "      <th>relevant_yn_confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>subject_matter</th>\n",
       "      <th>subject_matter_confidence</th>\n",
       "      <th>candidate_gold</th>\n",
       "      <th>...</th>\n",
       "      <th>relevant_yn_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>subject_matter_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697200650592256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199560069120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199312482304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697197118861312</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697196967903232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               candidate  candidate_confidence relevant_yn  \\\n",
       "0   1  No candidate mentioned                   1.0         yes   \n",
       "1   2            Scott Walker                   1.0         yes   \n",
       "2   3  No candidate mentioned                   1.0         yes   \n",
       "3   4  No candidate mentioned                   1.0         yes   \n",
       "4   5            Donald Trump                   1.0         yes   \n",
       "\n",
       "   relevant_yn_confidence sentiment  sentiment_confidence     subject_matter  \\\n",
       "0                     1.0   Neutral                0.6578  None of the above   \n",
       "1                     1.0  Positive                0.6333  None of the above   \n",
       "2                     1.0   Neutral                0.6629  None of the above   \n",
       "3                     1.0  Positive                1.0000  None of the above   \n",
       "4                     1.0  Positive                0.7045  None of the above   \n",
       "\n",
       "   subject_matter_confidence candidate_gold             ...              \\\n",
       "0                     1.0000            NaN             ...               \n",
       "1                     1.0000            NaN             ...               \n",
       "2                     0.6629            NaN             ...               \n",
       "3                     0.7039            NaN             ...               \n",
       "4                     1.0000            NaN             ...               \n",
       "\n",
       "  relevant_yn_gold retweet_count  sentiment_gold subject_matter_gold  \\\n",
       "0              NaN             5             NaN                 NaN   \n",
       "1              NaN            26             NaN                 NaN   \n",
       "2              NaN            27             NaN                 NaN   \n",
       "3              NaN           138             NaN                 NaN   \n",
       "4              NaN           156             NaN                 NaN   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...         NaN   \n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...         NaN   \n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...         NaN   \n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...         NaN   \n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...         NaN   \n",
       "\n",
       "               tweet_created            tweet_id  tweet_location  \\\n",
       "0  2015-08-07 09:54:46 -0700  629697200650592256             NaN   \n",
       "1  2015-08-07 09:54:46 -0700  629697199560069120             NaN   \n",
       "2  2015-08-07 09:54:46 -0700  629697199312482304             NaN   \n",
       "3  2015-08-07 09:54:45 -0700  629697197118861312           Texas   \n",
       "4  2015-08-07 09:54:45 -0700  629697196967903232             NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0                       Quito  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3  Central Time (US & Canada)  \n",
       "4                     Arizona  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...   Neutral\n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...   Neutral\n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keeping only the neccessary columns\n",
    "df = df[['text','sentiment']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13871, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    8493\n",
       "Neutral     3142\n",
       "Positive    2236\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2d56cbc16a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2d56cba5940>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.sentiment.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['sentiment'], test_size=0.33, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10428    RT @SalMasekela: These self righteous hypocrit...\n",
       "13671    RT @brock_a_r: I wonder which candidate is goi...\n",
       "89       A few of my favorite #Twitter responses to the...\n",
       "5024     @FoxNews Megyn Kelly's #GOPDebate performance ...\n",
       "8572     I didn't watch the #GOPDebates tonight, so I w...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10428    Negative\n",
       "13671    Negative\n",
       "89        Neutral\n",
       "5024     Negative\n",
       "8572     Negative\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;#]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z +_]')\n",
    "STOPWORDS = stopwords.words('english')\n",
    "STOPWORDS.extend(['rt', 'http']) # extend stopwords; rt means re-tweet\n",
    "STOPWORDS = set(STOPWORDS)\n",
    "\n",
    "def text_prepare(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join([word for word in text.split() if word not in STOPWORDS]) # delete stopwords from text\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[text_prepare(x) for x in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['salmasekela self righteous hypocrites trying god shameless gopdebates',\n",
       " 'brock_a_r wonder candidate going first accidentally call ben carson help gopdebates',\n",
       " 'favorite twitter responses gopdebate last night tco 2iqcdrcdlm tco 7tdma3vlm8',\n",
       " 'foxnews megyn kellys gopdebate performance every bit biased obnoxious candy crowleys 2012 cnn performance',\n",
       " 'didnt watch gopdebates tonight going ask figured']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val=[text_prepare(x) for x in X_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[text_prepare(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gopdebate', 4811),\n",
       " ('gopdebates', 2827),\n",
       " ('tco', 1941),\n",
       " ('rwsurfergirl', 1072),\n",
       " ('trump', 953),\n",
       " ('fox', 714),\n",
       " ('amp', 578),\n",
       " ('debate', 569),\n",
       " ('realdonaldtrump', 560),\n",
       " ('news', 504)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary of all words from train corpus with their counts.\n",
    "words_counts = {}\n",
    "\n",
    "from collections import Counter\n",
    "words_counts = Counter([word for line in X_train for word in line.split(' ')])\n",
    "\n",
    "# Sorting \n",
    "most_common_words = sorted(words_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Top 10\n",
    "most_common_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding with TF-IDF\n",
    "\n",
    "- Use class TfidfVectorizer from scikit-learn\n",
    "- Filter out too rare words (occur less than in 5 titles)\n",
    "- Filter out too frequent words (occur more than in 90% of the tweets).\n",
    "- Use 2-gram along with 1-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tfidf_features(X_train, X_val, X_test):\n",
    "    \"\"\"\n",
    "        X_train, X_val, X_test - input text       \n",
    "        return TF-IDF vectorizer for each dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    # filter out too rare words (occur less than in 5 titles) and too frequent words (occur more than in 90% of the tweets)\n",
    "    # ngram!!! -->  ngram_range=(1,2)\n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.9, min_df=5, token_pattern='(\\S+)')\n",
    "    \n",
    "    # Fit and transform the vectorizer on the train set\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    \n",
    "    # Transform the test and val sets \n",
    "    X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    return X_train_tfidf, X_val_tfidf, X_test_tfidf, tfidf_vectorizer.vocabulary_\n",
    "    \n",
    "    \n",
    "X_train_tfidf, X_val_tfidf, X_test_tfidf, tfidf_vocab = tfidf_features(X_train, X_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.40615562],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)-Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation mean accuracy 67.86%, std 0.38.\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Return accuracy\n",
    "scores = cross_val_score(logreg, X_train_tfidf, y_train, scoring='accuracy', n_jobs=-1, cv=3)\n",
    "\n",
    "print('Cross-validation mean accuracy {0:.2f}%, std {1:.2f}.'.format(np.mean(scores) * 100, np.std(scores) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=None, penalty='l2', random_state=None, solver='warn', tol=0.0001, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)-LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation mean accuracy 63.76%, std 0.45.\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC(dual=False)\n",
    "svc.fit(X_train_tfidf, y_train)\n",
    "\n",
    "\n",
    "scores = cross_val_score(svc, X_test_tfidf, y_test, scoring='accuracy', n_jobs=-1, cv=3)\n",
    "print('Cross-validation mean accuracy {0:.2f}%, std {1:.2f}.'.format(np.mean(scores) * 100, np.std(scores) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)-OneVsRest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(X_train, y_train):\n",
    "    \"\"\"\n",
    "      X_train, y_train — training text and sentiment\n",
    "      \n",
    "      return: trained classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create and fit LogisticRegression wraped into OneVsRestClassifier.\n",
    "    \n",
    "    model = OneVsRestClassifier(LogisticRegression(penalty='l2', C=1.0))\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "    \n",
    " \n",
    "classifier_tfidf = train_classifier(X_train_tfidf, y_train)\n",
    "\n",
    "y_val_predicted_labels_tfidf = classifier_tfidf.predict(X_val_tfidf)\n",
    "y_val_predicted_scores_tfidf = classifier_tfidf.decision_function(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf\n",
      "Accracy=0.6906939214631522\n",
      "F1_macro=0.5550930129562491\n",
      "F1_micro=0.6906939214631522\n",
      "F1_wted=0.6518652578108339\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def evaluation_scores(y_val, predicted):\n",
    "    \n",
    "    print (\"Accracy={}\".format(accuracy_score(y_val, predicted)))\n",
    "    print (\"F1_macro={}\".format(f1_score(y_val, predicted, average='macro')))\n",
    "    print (\"F1_micro={}\".format(f1_score(y_val, predicted, average='micro')))\n",
    "    print (\"F1_wted={}\".format(f1_score(y_val, predicted, average='weighted')))\n",
    "    \n",
    "print('Tfidf')\n",
    "evaluation_scores(y_val, y_val_predicted_labels_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF\n",
      "Accracy=0.6906939214631522\n",
      "F1_macro=0.5550930129562491\n",
      "F1_micro=0.6906939214631522\n",
      "F1_wted=0.6518652578108339\n"
     ]
    }
   ],
   "source": [
    "print('TFIDF')\n",
    "evaluation_scores(y_val,y_val_predicted_labels_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d)-LSTM with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[text_prepare(x) for x in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nancyleegrahn everyone feel climate change question last night exactly gopdebate',\n",
       " 'scottwalker didnt catch full gopdebate last night scotts best lines 90 seconds walker16 tco zsff',\n",
       " 'tjmshow mention tamir rice gopdebate held cleveland wow',\n",
       " 'robgeorge carly fiorina trending hours debate men justcompleted gopdebate says shes',\n",
       " 'danscavino gopdebate w realdonaldtrump delivered highest ratings history presidential debates trump2016 tco']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(X)\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,  248,  348,  340,  281,   46,   11,   18,\n",
       "         910,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "         251,   57, 1818,  485,    1,   11,   18,   97, 1290, 1433, 1217,\n",
       "         723,    3],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,  386,    1, 1666,\n",
       "         580,  419],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,  202,  156,  616,    8,  102,    1,\n",
       "         129,  668],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0, 1066,    1,  132,    7, 1999, 1553,  150,  541,   98,  106,\n",
       "         294,    3]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\69785hsh\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 24, 128)           256000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 24, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 591       \n",
      "=================================================================\n",
      "Total params: 511,391\n",
      "Trainable params: 511,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding the prediction column “sentiment” (Positive, Neutral, Negative)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=pd.get_dummies(df['sentiment']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the LSTM model for 20 epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trianing  (9293, 24) (9293, 3)\n",
      "Testing  (4578, 24) (4578, 3)\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      " - 7s - loss: 0.8404 - acc: 0.6425\n",
      "Epoch 2/20\n",
      " - 7s - loss: 0.6968 - acc: 0.7025\n",
      "Epoch 3/20\n",
      " - 7s - loss: 0.6350 - acc: 0.7316\n",
      "Epoch 4/20\n",
      " - 7s - loss: 0.5954 - acc: 0.7486\n",
      "Epoch 5/20\n",
      " - 7s - loss: 0.5648 - acc: 0.7606\n",
      "Epoch 6/20\n",
      " - 7s - loss: 0.5338 - acc: 0.7750\n",
      "Epoch 7/20\n",
      " - 7s - loss: 0.5102 - acc: 0.7824\n",
      "Epoch 8/20\n",
      " - 7s - loss: 0.4796 - acc: 0.7989\n",
      "Epoch 9/20\n",
      " - 7s - loss: 0.4579 - acc: 0.8088\n",
      "Epoch 10/20\n",
      " - 6s - loss: 0.4423 - acc: 0.8192\n",
      "Epoch 11/20\n",
      " - 6s - loss: 0.4196 - acc: 0.8241\n",
      "Epoch 12/20\n",
      " - 6s - loss: 0.4063 - acc: 0.8308\n",
      "Epoch 13/20\n",
      " - 7s - loss: 0.3906 - acc: 0.8396\n",
      "Epoch 14/20\n",
      " - 7s - loss: 0.3748 - acc: 0.8410\n",
      "Epoch 15/20\n",
      " - 7s - loss: 0.3596 - acc: 0.8504\n",
      "Epoch 16/20\n",
      " - 7s - loss: 0.3437 - acc: 0.8605\n",
      "Epoch 17/20\n",
      " - 7s - loss: 0.3385 - acc: 0.8581\n",
      "Epoch 18/20\n",
      " - 7s - loss: 0.3310 - acc: 0.8641\n",
      "Epoch 19/20\n",
      " - 7s - loss: 0.3205 - acc: 0.8673\n",
      "Epoch 20/20\n",
      " - 7s - loss: 0.3095 - acc: 0.8711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d56f0eaf28>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create train and test datasets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n",
    "print(\"Trianing \", X_train.shape,Y_train.shape)\n",
    "print(\"Testing \",X_test.shape,Y_test.shape)\n",
    "\n",
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, epochs = 20, batch_size=batch_size, verbose = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
